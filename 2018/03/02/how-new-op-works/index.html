<!DOCTYPE html>
<html>
<head>
    
<!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Google Analytics -->
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-108013148-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<!-- End Google Analytics -->


    
<!-- Tencent Speed -->
<script>var _speedMark = new Date()</script>
<!-- End Tencent Speed -->
<!-- Tencent Analysis -->
<script async src="//tajs.qq.com/stats?sId=63842673"></script>
<!-- End Tencent Analysis -->


    



    <meta charset="utf-8">
    
    
    
    <title>Tensorflow是如何注册和调用C++ New Op的 | Post Modern Paradigm | Kapok的技术博客</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="机器学习,深度学习,C++">
    <meta name="description" content="寒假回来想起来挖的坑，但好像并没有特别好的主题可以写，更不用说实习招聘近在眼前了，于是打算先扩展一下之前在知乎上的两个回答。 本文主要介绍动态链接的C++ New Op是如何被注册进来，又如何被Python代码调用的，也算是给自己的一个交代，毕竟本人一直不太喜欢high-level的API。本文大致分为三个模块：注册Ops，注册Kernel，调用Ops。 Ops的注册过程先说一下OpRegistr">
<meta name="keywords" content="机器学习,深度学习,C++">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow是如何注册和调用C++ New Op的">
<meta property="og:url" content="https://hikapok.github.io/2018/03/02/how-new-op-works/index.html">
<meta property="og:site_name" content="Post Modern Paradigm">
<meta property="og:description" content="寒假回来想起来挖的坑，但好像并没有特别好的主题可以写，更不用说实习招聘近在眼前了，于是打算先扩展一下之前在知乎上的两个回答。 本文主要介绍动态链接的C++ New Op是如何被注册进来，又如何被Python代码调用的，也算是给自己的一个交代，毕竟本人一直不太喜欢high-level的API。本文大致分为三个模块：注册Ops，注册Kernel，调用Ops。 Ops的注册过程先说一下OpRegistr">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2018-03-02T03:47:53.096Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tensorflow是如何注册和调用C++ New Op的">
<meta name="twitter:description" content="寒假回来想起来挖的坑，但好像并没有特别好的主题可以写，更不用说实习招聘近在眼前了，于是打算先扩展一下之前在知乎上的两个回答。 本文主要介绍动态链接的C++ New Op是如何被注册进来，又如何被Python代码调用的，也算是给自己的一个交代，毕竟本人一直不太喜欢high-level的API。本文大致分为三个模块：注册Ops，注册Kernel，调用Ops。 Ops的注册过程先说一下OpRegistr">
    
        <link rel="alternate" type="application/atom+xml" title="Post Modern Paradigm" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/logo.png">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    

</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/head_logo.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Kapok</h5>
          <a href="mailto:wangchangan@yeah.net" title="wangchangan@yeah.net" class="mail">wangchangan@yeah.net</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/HiKapok" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://www.zhihu.com/people/mangost/activities" target="_blank" >
                <i class="icon icon-lg icon-link"></i>
                Zhihu
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://twitter.com/HiKapok" target="_blank" >
                <i class="icon icon-lg icon-twitter"></i>
                Twitter
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/about" target="_blank" >
                <i class="icon icon-lg icon-user"></i>
                About
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Tensorflow是如何注册和调用C++ New Op的</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Tensorflow是如何注册和调用C++ New Op的</h1>
        <h5 class="subtitle">
            
                <time datetime="2018-03-02T02:52:15.000Z" itemprop="datePublished" class="page-time">
  2018-03-02
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/deeplearning/">深度学习</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Ops的注册过程"><span class="post-toc-number">1.</span> <span class="post-toc-text">Ops的注册过程</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Kernel的注册过程"><span class="post-toc-number">2.</span> <span class="post-toc-text">Kernel的注册过程</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#OpKernel的创建与调用"><span class="post-toc-number">3.</span> <span class="post-toc-text">OpKernel的创建与调用</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#注册Ops和Kernel后传"><span class="post-toc-number">4.</span> <span class="post-toc-text">注册Ops和Kernel后传</span></a></li></ol>
        </nav>
    </aside>
    
<article id="post-how-new-op-works"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Tensorflow是如何注册和调用C++ New Op的</h1>
        <div class="post-meta">
            <time class="post-time" title="2018-03-02 10:52:15" datetime="2018-03-02T02:52:15.000Z"  itemprop="datePublished">2018-03-02</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/deeplearning/">深度学习</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>寒假回来想起来挖的坑，但好像并没有特别好的主题可以写，更不用说实习招聘近在眼前了，于是打算先扩展一下之前在知乎上的两个回答。</p>
<p>本文主要介绍动态链接的C++ New Op是如何被注册进来，又如何被Python代码调用的，也算是给自己的一个交代，毕竟本人一直不太喜欢high-level的API。本文大致分为三个模块：注册Ops，注册Kernel，调用Ops。</p>
<h1 id="Ops的注册过程"><a href="#Ops的注册过程" class="headerlink" title="Ops的注册过程"></a><strong>Ops的注册过程</strong></h1><p>先说一下OpRegistrationData这个东西，这个类的对象由全局注册器Registry负责分配，作用简单来说就是保存OpDef和OpShapeInferenceFn函数，前者保存有Op的各种具体信息，会由OpDefBuilder在最后的解析参数时（成员函数Finalize）放进来，后者在SetShapeFn传进来（由Wrapper转发），所谓注册就是将op name和OpRegistrationData关联起来，具体来说放进hashmap。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">mutable</span> <span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>, <span class="keyword">const</span> OpRegistrationData*&gt; registry_;</div></pre></td></tr></table></figure></p>
<p>还得先说一下OpDefBuilder这个类，OpDefBuilder会负责接收Op的各种属性和参数定义（就是REGISTER_OP时指定的，见下），最后统一解析（注意只是解析并不保证合法性之类的）并转给OpRegistrationData这个类（包括ShapeFn）。</p>
<p>我们自己注册op都会通过下面这个宏定义：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">REGISTER_OP(<span class="string">"YourOp"</span>)</div><div class="line">   .Attr(<span class="string">"T: &#123;float&#125;"</span>)</div><div class="line">   .Input(<span class="string">"logits: T"</span>)</div><div class="line">   .Input(<span class="string">"Labels: T"</span>)</div><div class="line">   .Output(<span class="string">"loss: T"</span>)</div><div class="line">   .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) &#123;</div><div class="line">     c-&gt;set_output(<span class="number">0</span>, c-&gt;MakeShape(&#123;<span class="number">1</span>&#125;));</div><div class="line">     <span class="keyword">return</span> Status::OK();</div><div class="line">   &#125;);</div></pre></td></tr></table></figure></p>
<p>细节都在REGISTER_OP那个宏定义里面，简化如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">static OpDefBuilderReceiver register_op = OpDefBuilderWrapper('YourOp')</div></pre></td></tr></table></figure></p>
<p>其中OpDefBuilderWrapper内部保存有一个OpDefBuilder成员变量，你所有对REGISTER_OP宏连续调用的操作包括op的名字最后都会一股脑转发给前面那个唯一的OpDefBuilder变量，而OpDefBuilderReceiver则拿过来BuilderWrapper交给一个负责管理所有Op注册的Registry，Registry暴露Register方法给op们注册，把官方的example摘过来示意一下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//Example registration:</span></div><div class="line">  OpRegistry::Global()-&gt;Register(</div><div class="line">    [](OpRegistrationData* op_reg_data)-&gt;Status &#123;</div><div class="line">      <span class="comment">// Populate *op_reg_data here.</span></div><div class="line">      <span class="keyword">return</span> Status::OK();</div><div class="line">  &#125;);</div></pre></td></tr></table></figure></p>
<p>（先解释下：OpRegistry::Global()简单的单例模式，返回OpRegistry的全局唯一实例，当然这里必须要感谢下新标准对static线程安全的保证。）</p>
<p>在那个lambda里面你就可以做任何想做的事情了，比如就像OpDefBuilderReceiver一样把BuilderWrapper拿进来，然后把wrapper去掉取出OpDefBuilder，看到上面lambda里面那个op_reg_data没，对这就是之前提到的将解析好参数及shapefn传到OpRegistrationData里，最后Register拿到op的name和OpRegistrationData组成pair放进hashmap完成注册，同时会做一些合法性检查的事情。如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">OpRegistry::Global()-&gt;Register(</div><div class="line">      [wrapper](OpRegistrationData* op_reg_data) -&gt; Status &#123;</div><div class="line">        <span class="keyword">return</span> wrapper.builder().Finalize(op_reg_data);</div><div class="line">      &#125;);</div></pre></td></tr></table></figure></p>
<p>其实到这里真正的注册并不一定会发生，下面会详细说。</p>
<h1 id="Kernel的注册过程"><a href="#Kernel的注册过程" class="headerlink" title="Kernel的注册过程"></a><strong>Kernel的注册过程</strong></h1><p>与Ops的注册类似，也是有一个叫作KernelDefBuilder的wrapper，内部保存有KernelDef的一个指针，用于设置各种属性，最后调用Build函数可返回该指针并清空Builder，Kernel的注册主要是通过下面这个宏来实现的：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">REGISTER_KERNEL_BUILDER(                                       \</div><div class="line">      Name(<span class="string">"PsRoiAlignGrad"</span>).Device(DEVICE_GPU).TypeConstraint&lt;<span class="keyword">float</span>&gt;(<span class="string">"T"</span>), \</div><div class="line">      PSROIAlignGradOp&lt;GPUDevice, <span class="keyword">float</span>&gt;);</div></pre></td></tr></table></figure></p>
<p>其中Name是KernelDefBuilder的一个派生类，Name(“KernelName”)会首先创建一个KernelDefBuilder同时设置设置kernel名称，每次调用这种setter函数就会返回Builder自身从而支持连续调用，然后是设置Device，最后添加值float到属性T中。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Name</span> :</span> <span class="keyword">public</span> KernelDefBuilder &#123;</div><div class="line"> <span class="keyword">public</span>:</div><div class="line">  <span class="comment">// For system kernels, we ignore selective registration and</span></div><div class="line">  <span class="comment">// unconditionally register the kernel.</span></div><div class="line">  explicit Name(const char* op) : KernelDefBuilder(op) &#123;&#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>REGISTER_KERNEL_BUILDER宏里面就是一些trick，实质是创建一个名称唯一的类型为OpKernelRegistrar的全局静态变量，如果你有兴趣可以看一下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">define</span> REGISTER_KERNEL_BUILDER(kernel_builder, ...) \</span></div><div class="line">  REGISTER_KERNEL_BUILDER_UNIQ_HELPER(__COUNTER__, kernel_builder, __VA_ARGS__)</div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> REGISTER_KERNEL_BUILDER_UNIQ_HELPER(ctr, kernel_builder, ...) \</span></div><div class="line">  REGISTER_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, __VA_ARGS__)</div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> REGISTER_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, ...)        \</span></div><div class="line">  <span class="keyword">constexpr</span> <span class="keyword">bool</span> should_register_#<span class="meta">#ctr##__flag =                      \</span></div><div class="line">      SHOULD_REGISTER_OP_KERNEL(#__VA_ARGS__);                        \</div><div class="line">  <span class="keyword">static</span> ::tensorflow::kernel_factory::OpKernelRegistrar              \</div><div class="line">      registrar__body__#<span class="meta">#ctr##__object(                               \</span></div><div class="line">          should_register_#<span class="meta">#ctr##__flag                               \</span></div><div class="line">              ? ::tensorflow::register_kernel::kernel_builder.Build() \</div><div class="line">              : <span class="literal">nullptr</span>,                                              \</div><div class="line">          #__VA_ARGS__,                                               \</div><div class="line">          [](::tensorflow::OpKernelConstruction* context)             \</div><div class="line">              -&gt; ::tensorflow::OpKernel* &#123;                            \</div><div class="line">            <span class="keyword">return</span> <span class="keyword">new</span> __VA_ARGS__(context);                          \</div><div class="line">          &#125;);</div></pre></td></tr></table></figure>
<p>OpKernelRegistrar静态变量的构造需要三个参数，如下所示，第一个是KernelDef，第二个是定义Kernel的类名，第三个是创建kernel对象的函数，其实后面就可以知道这三个参数都会被包装到KernelRegistration这个结构体里，然后作为Kernel注册表的值。因此这个宏会首先调用KernelDefBuilder的Build函数获得对应的KernelDef；然后获取用于创建这个Kernel的C++类名称（这个类是继承自OpKernel的）；最后包装一个factory函数用来接收传进来的OpKernelConstruction*，创建对应的Kernel类对象，并返回其指针。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpKernelRegistrar</span> &#123;</span></div><div class="line"> <span class="keyword">public</span>:</div><div class="line">  <span class="keyword">typedef</span> OpKernel* (*Factory)(OpKernelConstruction*);</div><div class="line"></div><div class="line">  OpKernelRegistrar(<span class="keyword">const</span> KernelDef* kernel_def, StringPiece kernel_class_name,</div><div class="line">                    Factory factory) &#123;</div><div class="line">    <span class="keyword">if</span> (kernel_def != <span class="literal">nullptr</span>) &#123;</div><div class="line">      InitInternal(kernel_def, kernel_class_name, factory);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>这里是<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/framework/op_kernel.cc#L909" target="_blank" rel="external">InitInternal</a>的细节<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> OpKernelRegistrar::InitInternal(<span class="keyword">const</span> KernelDef* kernel_def,</div><div class="line">                                     StringPiece kernel_class_name,</div><div class="line">                                     Factory factory) &#123;</div><div class="line">  <span class="comment">// See comments in register_kernel::Name in header for info on _no_register.</span></div><div class="line">  <span class="keyword">if</span> (kernel_def-&gt;op() != <span class="string">"_no_register"</span>) &#123;</div><div class="line">    <span class="keyword">const</span> <span class="built_in">string</span> key =</div><div class="line">        Key(kernel_def-&gt;op(), DeviceType(kernel_def-&gt;device_type()),</div><div class="line">            kernel_def-&gt;label());</div><div class="line">    GlobalKernelRegistryTyped()-&gt;insert(<span class="built_in">std</span>::make_pair(</div><div class="line">        key, KernelRegistration(*kernel_def, kernel_class_name, factory)));</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">delete</span> kernel_def;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>可以看到OpKernelRegistrar这个类主要是负责根据传进来的KernelDef和KernelFactory，首先依据一定规则生成一个适当的key，并插入到一个全局唯一的Kernel注册表里，注册表当然是一个map但是值得注意的是它是multimap因此支持一个键对应多个kernel副本。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="built_in">std</span>::<span class="built_in">unordered_multimap</span>&lt;<span class="built_in">string</span>, KernelRegistration&gt; KernelRegistry;</div></pre></td></tr></table></figure></p>
<h1 id="OpKernel的创建与调用"><a href="#OpKernel的创建与调用" class="headerlink" title="OpKernel的创建与调用"></a><strong>OpKernel的创建与调用</strong></h1><p>如果你还记得的话，前面还有一个全局的OpRegistry，这样根据NodeDef里的Op名称就可以获得Op对应的信息，再结合设备类型也就可以获得Kernel对应的信息了，而NodeDef是在Python创建Operation之前创建的，可以看这里<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/ops.py#L3086" target="_blank" rel="external">create_op</a>，后面会提到调用这个函数的地方。</p>
<p>然后就可以根据一个NodeDef和当前的设备类型在运行时创建一个OpKernel了，每个被创建的OpKernel都会被自动地管理生命周期。在<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/device.h#L165" target="_blank" rel="external">Device</a>类中会有一个OpSegment对象，<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/framework/op_segment.h#L31" target="_blank" rel="external">OpSegment</a>会管理一个sessions中用到的kernel，根据情况来决定是创建新的还是复用之前的OpKernel，具体来说是有两个嵌套的hashmap，第一个将session handle映射到一个KernelMap，然后在KernelMap就可以去查找是否有对应Op名的OpKernel，如果没有就调用一个create_fn函数进行创建。</p>
<p>那么问题来了，这背后的原动力在哪？事实上Session在第一次为某个Node创建Executor的时候这一切就发生了（后面会再说到Executor的）：<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/direct_session.cc#L1064" target="_blank" rel="external">DirectSession::GetOrCreateExecutors</a>，更直接地可以看查找失败后第一次创建Executor的<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/direct_session.cc#L1202" target="_blank" rel="external">地方</a>，代码片段如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">LocalExecutorParams params;</div><div class="line">params.device = device;</div><div class="line">params.function_library = lib;</div><div class="line"><span class="keyword">auto</span> opseg = device-&gt;op_segment();</div><div class="line">params.create_kernel = [<span class="keyword">this</span>, lib, opseg](<span class="keyword">const</span> NodeDef&amp; ndef, OpKernel** kernel) &#123;</div><div class="line">  <span class="comment">// We do not share the kernel via the OpSegment if the node is</span></div><div class="line">  <span class="comment">// stateless, or a function.</span></div><div class="line">  <span class="comment">// NOTE(mrry): We must not share function kernels (implemented</span></div><div class="line">  <span class="comment">// using `CallOp`) between subgraphs, because `CallOp::handle_`</span></div><div class="line">  <span class="comment">// is tied to a particular subgraph. Even if the function itself</span></div><div class="line">  <span class="comment">// is stateful, the `CallOp` that invokes it is not.</span></div><div class="line">  <span class="keyword">if</span> (!lib-&gt;IsStateful(ndef.op()) ||</div><div class="line">	  lib-&gt;GetFunctionLibraryDefinition()-&gt;Find(ndef.op()) != <span class="literal">nullptr</span>) &#123;</div><div class="line">	<span class="keyword">return</span> lib-&gt;CreateKernel(ndef, kernel);</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">auto</span> create_fn = [lib, &amp;ndef](OpKernel** kernel) &#123;</div><div class="line">	<span class="keyword">return</span> lib-&gt;CreateKernel(ndef, kernel);</div><div class="line">  &#125;;</div><div class="line">  <span class="comment">// Kernels created for subgraph nodes need to be cached.  On</span></div><div class="line">  <span class="comment">// cache miss, create_fn() is invoked to create a kernel based</span></div><div class="line">  <span class="comment">// on the function library here + global op registry.</span></div><div class="line">  <span class="keyword">return</span> opseg-&gt;FindOrCreate(session_handle_, ndef.name(), kernel,</div><div class="line">							 create_fn);</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>可以看到取出OpSegment，构造create_fn并调用FindOrCreate的过程。其中create_fn内部调用的FunctionLibraryRuntime的CreateKernel函数可以看这里：<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/function.cc#L366" target="_blank" rel="external">FunctionLibraryRuntimeImpl::CreateKernel</a>，再往下<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/executor.cc#L2621" target="_blank" rel="external">CreateNonCachedKernel</a>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function">Status <span class="title">CreateNonCachedKernel</span><span class="params">(Device* device, FunctionLibraryRuntime* flib,</span></span></div><div class="line"><span class="function"><span class="params">                             <span class="keyword">const</span> NodeDef&amp; ndef, <span class="keyword">int</span> graph_def_version,</span></span></div><div class="line"><span class="function"><span class="params">                             OpKernel** kernel)</span> </span>&#123;</div><div class="line">  <span class="keyword">const</span> <span class="keyword">auto</span> device_type = DeviceType(device-&gt;attributes().device_type());</div><div class="line">  <span class="keyword">auto</span> allocator = device-&gt;GetAllocator(AllocatorAttributes());</div><div class="line">  <span class="keyword">return</span> CreateOpKernel(device_type, device, allocator, flib, ndef,</div><div class="line">                        graph_def_version, kernel);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>看到了CreateOpKernel的调用，这下总算回到了我们最开始的地方<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/core/framework/op_kernel.cc#L1059" target="_blank" rel="external">CreateOpKernel</a>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function">Status <span class="title">CreateOpKernel</span><span class="params">(DeviceType device_type, DeviceBase* device,</span></span></div><div class="line"><span class="function"><span class="params">                      Allocator* allocator, FunctionLibraryRuntime* flib,</span></span></div><div class="line"><span class="function"><span class="params">                      <span class="keyword">const</span> NodeDef&amp; node_def, <span class="keyword">int</span> graph_def_version,</span></span></div><div class="line"><span class="function"><span class="params">                      OpKernel** kernel)</span></span></div></pre></td></tr></table></figure>
<p>这个核心函数主要是做一下以下几件事情：根据node_def取出op名，去查OpRegistry，并与node_def的信息进行校验，比如接口是否一致，node_def中是否包含所有op_def中的信息等，然后根据device_type和op名去查KernelRegistry获取KernelRegistration，就是map中的值，包含之前提到的三项<br>接着是确定输入输出类型及其存储位置，最后是创建一个OpKernelConstruction对象，并传给Kernel的factory函数函数，这就到了用户自己写的函数这边了：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Everything needed for OpKernel construction.</span></div><div class="line"><span class="function">OpKernelConstruction <span class="title">context</span><span class="params">(</span></span></div><div class="line"><span class="function"><span class="params">  device_type, device, allocator, &amp;node_def, op_def, flib, inputs,</span></span></div><div class="line"><span class="function"><span class="params">  input_memory_types, outputs, output_memory_types, graph_def_version, &amp;s)</span></span>;</div><div class="line">*kernel = (*registration-&gt;factory)(&amp;context);</div></pre></td></tr></table></figure>
<p>Kernel创建完了，那么它什么时候被执行呢？前面说到第一次创建executor的时候会创建OpKernel，其实每次Session调用Run的时候最终也是转到executor这边来执行的，包括根据当前的运行时环境创建OpKernelContext以及<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/executor.cc#L1656" target="_blank" rel="external">OpKernel::Compute的调用</a>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Synchronous computes.</span></div><div class="line"><span class="function">OpKernelContext <span class="title">ctx</span><span class="params">(&amp;params, item.num_outputs)</span></span>;</div><div class="line">nodestats::SetOpStart(stats);</div><div class="line">device-&gt;Compute(CHECK_NOTNULL(op_kernel), &amp;ctx);</div><div class="line">nodestats::SetOpEnd(stats);</div></pre></td></tr></table></figure>
<p>其中device-&gt;Compute这一步通过查看基类的实现就大概能知道所有细节了<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/device.h#L82" target="_blank" rel="external">Device::Compute</a>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Performs the actual compute function.</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// Subclasses may override this function if they wish to perform</span></div><div class="line"><span class="comment">// some initialization before each compute.</span></div><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Compute</span><span class="params">(OpKernel* op_kernel, OpKernelContext* context)</span> </span>&#123;</div><div class="line">  op_kernel-&gt;Compute(context);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>可以发现，我们写的Compute方法在这里就被调用了。至此故事好像可以告一段落了，不过说了半天好像一直在C++这边啊，那Python代码怎么调用的呢？</p>
<h1 id="注册Ops和Kernel后传"><a href="#注册Ops和Kernel后传" class="headerlink" title="注册Ops和Kernel后传"></a><strong>注册Ops和Kernel后传</strong></h1><p>根据上面REGISTER_KERNEL_BUILDER所展开的两段程序很容易就判断出如果动态库被加载进来的话，Kernel就会自动完成注册，这跟Ops的注册基本是一样的，不同之处在于动态链接进来的Ops会在加载库之前设置延迟注册的标记，并添加一个Watcher，然后手动调用注册，这主要是为了通过Watcher获取注册过程中从OpRegistrationData（就是注册表的值）中取出的OpDef，这一点可以在后面的LoadLibrary中看到。这个过程很重要，通过获得的OpDef组成的OpList并序列化后，Python端就可以解析出这些OpDef，同时调用C++这边利用这些OpDef生成对应的ApiDef，二者结合就可以动态生成定义这个Op的Python代码，然后返回到Python端执行这些代码，注意这些代码的执行并不包括创建Op并添加到Graph这个过程，只包括定义相关代码段的函数，下面是从Python端load_op_library一直到生成Python代码的过程：<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/load_library.py#L73" target="_blank" rel="external">load_op_library</a>-&gt;<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/python_op_gen.cc#L866" target="_blank" rel="external">GetPythonWrappers</a>-&gt;<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/python_op_gen.cc#L776" target="_blank" rel="external">GetPythonOps</a>-&gt;<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/python_op_gen.cc#L770" target="_blank" rel="external">GetPythonOp</a>-&gt;<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/python_op_gen.cc#L478" target="_blank" rel="external">GenPythonOp::Code()</a>。还有从OpList生成ApiDef的地方<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/framework/op_gen_lib.cc#L471" target="_blank" rel="external">ApiDefMap::ApiDefMap(const OpList&amp; op_list)</a>。如果你有兴趣的话可以去看一下我之前写的一个Op自动生成的代码，我附在了本文最后，生成代码中的apply_op就是添加Op到Graph的代码，可以看这里<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/op_def_library.py#L294" target="_blank" rel="external">apply_op</a>，这个函数的最后面就是前面提到的调用Graph的create_op。</p>
<p>下面是LoadLibrary的代码段，可以对照一下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="function">Status <span class="title">LoadLibrary</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* library_filename, <span class="keyword">void</span>** result,</span></span></div><div class="line"><span class="function"><span class="params">                   <span class="keyword">const</span> <span class="keyword">void</span>** buf, <span class="keyword">size_t</span>* len)</span> </span>&#123;</div><div class="line">  <span class="keyword">static</span> mutex mu;</div><div class="line">  <span class="keyword">static</span> <span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>, Library&gt; loaded_libs;</div><div class="line">  Env* env = Env::Default();</div><div class="line">  Library library;</div><div class="line">  <span class="built_in">std</span>::<span class="built_in">unordered_set</span>&lt;<span class="built_in">string</span>&gt; seen_op_names;</div><div class="line">  &#123;</div><div class="line">    <span class="function">mutex_lock <span class="title">lock</span><span class="params">(mu)</span></span>;</div><div class="line">    <span class="keyword">if</span> (loaded_libs.find(library_filename) != loaded_libs.end()) &#123;</div><div class="line">      library = loaded_libs[library_filename];</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      Status s = OpRegistry::Global()-&gt;ProcessRegistrations();</div><div class="line">      <span class="keyword">if</span> (!s.ok()) &#123;</div><div class="line">        <span class="keyword">return</span> s;</div><div class="line">      &#125;</div><div class="line">      TF_RETURN_IF_ERROR(OpRegistry::Global()-&gt;SetWatcher(</div><div class="line">          [&amp;library, &amp;seen_op_names](<span class="keyword">const</span> Status&amp; s,</div><div class="line">                                     <span class="keyword">const</span> OpDef&amp; opdef) -&gt; Status &#123;</div><div class="line">            <span class="keyword">if</span> (errors::IsAlreadyExists(s)) &#123;</div><div class="line">              <span class="keyword">if</span> (seen_op_names.find(opdef.name()) == seen_op_names.end()) &#123;</div><div class="line">                <span class="comment">// Over writing a registration of an op not in this custom op</span></div><div class="line">                <span class="comment">// library. Treat this as not an error.</span></div><div class="line">                <span class="keyword">return</span> Status::OK();</div><div class="line">              &#125;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span> (s.ok()) &#123;</div><div class="line">              *library.op_list.add_op() = opdef;</div><div class="line">              seen_op_names.insert(opdef.name());</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">return</span> s;</div><div class="line">          &#125;));</div><div class="line">      OpRegistry::Global()-&gt;DeferRegistrations();</div><div class="line">      s = env-&gt;LoadLibrary(library_filename, &amp;library.handle);</div><div class="line">      <span class="keyword">if</span> (s.ok()) &#123;</div><div class="line">        s = OpRegistry::Global()-&gt;ProcessRegistrations();</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (!s.ok()) &#123;</div><div class="line">        OpRegistry::Global()-&gt;ClearDeferredRegistrations();</div><div class="line">        TF_RETURN_IF_ERROR(OpRegistry::Global()-&gt;SetWatcher(<span class="literal">nullptr</span>));</div><div class="line">        <span class="keyword">return</span> s;</div><div class="line">      &#125;</div><div class="line">      TF_RETURN_IF_ERROR(OpRegistry::Global()-&gt;SetWatcher(<span class="literal">nullptr</span>));</div><div class="line"></div><div class="line">      loaded_libs[library_filename] = library;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="built_in">string</span> str;</div><div class="line">  library.op_list.SerializeToString(&amp;str);</div><div class="line">  <span class="keyword">char</span>* str_buf = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">char</span>*&gt;(port::Malloc(str.length()));</div><div class="line">  <span class="built_in">memcpy</span>(str_buf, str.data(), str.length());</div><div class="line">  *buf = str_buf;</div><div class="line">  *len = str.length();</div><div class="line"></div><div class="line">  *result = library.handle;</div><div class="line">  <span class="keyword">return</span> Status::OK();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>自动生成的Python代码，这里是对应的<a href="https://github.com/HiKapok/PSROIAlign" target="_blank" rel="external">C++ Op</a>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div></pre></td><td class="code"><pre><div class="line"><span class="string">"""Python wrappers around TensorFlow ops.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">This file is MACHINE GENERATED! Do not edit.</span></div><div class="line"><span class="string">"""</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> collections <span class="keyword">as</span> _collections</div><div class="line"></div><div class="line"><span class="keyword">from</span> tensorflow.core.framework <span class="keyword">import</span> op_def_pb2 <span class="keyword">as</span> _op_def_pb2</div><div class="line"></div><div class="line"><span class="comment"># Needed to trigger the call to _set_call_cpp_shape_fn.</span></div><div class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> common_shapes <span class="keyword">as</span> _common_shapes</div><div class="line"></div><div class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> op_def_registry <span class="keyword">as</span> _op_def_registry</div><div class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> ops <span class="keyword">as</span> _ops</div><div class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> op_def_library <span class="keyword">as</span> _op_def_library</div><div class="line"><span class="keyword">from</span> tensorflow.python.util.tf_export <span class="keyword">import</span> tf_export</div><div class="line"></div><div class="line">_ps_roi_align_outputs = [<span class="string">"pooled_features"</span>, <span class="string">"pooled_index"</span>]</div><div class="line">_PsRoiAlignOutput = _collections.namedtuple(</div><div class="line">    <span class="string">"PsRoiAlign"</span>, _ps_roi_align_outputs)</div><div class="line"></div><div class="line"></div><div class="line"><span class="meta">@tf_export('ps_roi_align')</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ps_roi_align</span><span class="params">(inputs, rois, grid_dim_width, grid_dim_height, name=None)</span>:</span></div><div class="line">  <span class="string">r"""        PsRoiAlign is a new PsRoiPooling method without align problems.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">          The input rois to be pooled must in format [center_y, center_x, h, w] and each element must be in range [0, 1.].</span></div><div class="line"><span class="string">          The caller must make sure that all rois is valid (has a intersect region (one pixel at least) with the window [0.5, 0.5, 1., 1.]).</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Args:</span></div><div class="line"><span class="string">    inputs: A `Tensor`. Must be one of the following types: `float32`.</span></div><div class="line"><span class="string">    rois: A `Tensor`. Must have the same type as `inputs`.</span></div><div class="line"><span class="string">    grid_dim_width: An `int`.</span></div><div class="line"><span class="string">    grid_dim_height: An `int`.</span></div><div class="line"><span class="string">    name: A name for the operation (optional).</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Returns:</span></div><div class="line"><span class="string">    A tuple of `Tensor` objects (pooled_features, pooled_index).</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    pooled_features: A `Tensor`. Has the same type as `inputs`.</span></div><div class="line"><span class="string">    pooled_index: A `Tensor` of type `int32`.</span></div><div class="line"><span class="string">  """</span></div><div class="line">  _result = _op_def_lib.apply_op(<span class="string">"PsRoiAlign"</span>, inputs=inputs, rois=rois,</div><div class="line">                                 grid_dim_width=grid_dim_width,</div><div class="line">                                 grid_dim_height=grid_dim_height, name=name)</div><div class="line">  _result = _PsRoiAlignOutput._make(_result)</div><div class="line">  <span class="keyword">return</span> _result</div><div class="line"></div><div class="line"></div><div class="line">_ops.RegisterShape(<span class="string">"PsRoiAlign"</span>)(<span class="keyword">None</span>)</div><div class="line"></div><div class="line"><span class="meta">@tf_export('ps_roi_align_grad')</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ps_roi_align_grad</span><span class="params">(inputs, rois, pooled_features_grad, pooled_index, grid_dim_width, grid_dim_height, name=None)</span>:</span></div><div class="line">  <span class="string">r"""        PsRoiAlignGrad is the Gradient op of PsRoiAlign.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">          The input rois to be pooled must in format [center_y, center_x, h, w] and each element must be in range [0, 1.].</span></div><div class="line"><span class="string">          The caller must make sure that all rois is valid (has a intersect region (one pixel at least) with the window [0.5, 0.5, 1., 1.]).</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Args:</span></div><div class="line"><span class="string">    inputs: A `Tensor`. Must be one of the following types: `float32`.</span></div><div class="line"><span class="string">    rois: A `Tensor`. Must have the same type as `inputs`.</span></div><div class="line"><span class="string">    pooled_features_grad: A `Tensor`. Must have the same type as `inputs`.</span></div><div class="line"><span class="string">    pooled_index: A `Tensor` of type `int32`.</span></div><div class="line"><span class="string">    grid_dim_width: An `int`.</span></div><div class="line"><span class="string">    grid_dim_height: An `int`.</span></div><div class="line"><span class="string">    name: A name for the operation (optional).</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Returns:</span></div><div class="line"><span class="string">    A `Tensor`. Has the same type as `inputs`.</span></div><div class="line"><span class="string">  """</span></div><div class="line">  _result = _op_def_lib.apply_op(<span class="string">"PsRoiAlignGrad"</span>, inputs=inputs, rois=rois,</div><div class="line">                                 pooled_features_grad=pooled_features_grad,</div><div class="line">                                 pooled_index=pooled_index,</div><div class="line">                                 grid_dim_width=grid_dim_width,</div><div class="line">                                 grid_dim_height=grid_dim_height, name=name)</div><div class="line">  <span class="keyword">return</span> _result</div><div class="line"></div><div class="line"></div><div class="line">_ops.RegisterShape(<span class="string">"PsRoiAlignGrad"</span>)(<span class="keyword">None</span>)</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_InitOpDefLibrary</span><span class="params">(op_list_proto_bytes)</span>:</span></div><div class="line">  op_list = _op_def_pb2.OpList()</div><div class="line">  op_list.ParseFromString(op_list_proto_bytes)</div><div class="line">  _op_def_registry.register_op_list(op_list)</div><div class="line">  op_def_lib = _op_def_library.OpDefLibrary()</div><div class="line">  op_def_lib.add_op_list(op_list)</div><div class="line">  <span class="keyword">return</span> op_def_lib</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># op &#123;</span></div><div class="line"><span class="comment">#   name: "PsRoiAlign"</span></div><div class="line"><span class="comment">#   input_arg &#123;</span></div><div class="line"><span class="comment">#     name: "inputs"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   input_arg &#123;</span></div><div class="line"><span class="comment">#     name: "rois"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   output_arg &#123;</span></div><div class="line"><span class="comment">#     name: "pooled_features"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   output_arg &#123;</span></div><div class="line"><span class="comment">#     name: "pooled_index"</span></div><div class="line"><span class="comment">#     type: DT_INT32</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   attr &#123;</span></div><div class="line"><span class="comment">#     name: "T"</span></div><div class="line"><span class="comment">#     type: "type"</span></div><div class="line"><span class="comment">#     allowed_values &#123;</span></div><div class="line"><span class="comment">#       list &#123;</span></div><div class="line"><span class="comment">#         type: DT_FLOAT</span></div><div class="line"><span class="comment">#       &#125;</span></div><div class="line"><span class="comment">#     &#125;</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   attr &#123;</span></div><div class="line"><span class="comment">#     name: "grid_dim_width"</span></div><div class="line"><span class="comment">#     type: "int"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   attr &#123;</span></div><div class="line"><span class="comment">#     name: "grid_dim_height"</span></div><div class="line"><span class="comment">#     type: "int"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment"># &#125;</span></div><div class="line"><span class="comment"># op &#123;</span></div><div class="line"><span class="comment">#   name: "PsRoiAlignGrad"</span></div><div class="line"><span class="comment">#   input_arg &#123;</span></div><div class="line"><span class="comment">#     name: "inputs"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   input_arg &#123;</span></div><div class="line"><span class="comment">#     name: "rois"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   input_arg &#123;</span></div><div class="line"><span class="comment">#     name: "pooled_features_grad"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   input_arg &#123;</span></div><div class="line"><span class="comment">#     name: "pooled_index"</span></div><div class="line"><span class="comment">#     type: DT_INT32</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   output_arg &#123;</span></div><div class="line"><span class="comment">#     name: "grad_output"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   attr &#123;</span></div><div class="line"><span class="comment">#     name: "T"</span></div><div class="line"><span class="comment">#     type: "type"</span></div><div class="line"><span class="comment">#     allowed_values &#123;</span></div><div class="line"><span class="comment">#       list &#123;</span></div><div class="line"><span class="comment">#         type: DT_FLOAT</span></div><div class="line"><span class="comment">#       &#125;</span></div><div class="line"><span class="comment">#     &#125;</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   attr &#123;</span></div><div class="line"><span class="comment">#     name: "grid_dim_width"</span></div><div class="line"><span class="comment">#     type: "int"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   attr &#123;</span></div><div class="line"><span class="comment">#     name: "grid_dim_height"</span></div><div class="line"><span class="comment">#     type: "int"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment"># &#125;</span></div><div class="line">_op_def_lib = _InitOpDefLibrary(<span class="string">b"\\n\\215\\001\\n\\nPsRoiAlign\\022\\013\\n\\006inputs\\"</span>\\<span class="number">001</span>T\\<span class="number">022</span>\\t\\n\\<span class="number">004</span>rois\\<span class="string">"\\001T\\032\\024\\n\\017pooled_features\\"</span>\\<span class="number">001</span>T\\<span class="number">032</span>\\<span class="number">020</span>\\n\\<span class="number">014</span>pooled_index\\<span class="number">030</span>\\<span class="number">003</span>\\<span class="string">"\\020\\n\\001T\\022\\004type:\\005\\n\\0032\\001\\001\\"</span>\\<span class="number">025</span>\\n\\<span class="number">016</span>grid_dim_width\\<span class="number">022</span>\\<span class="number">003</span>int\\<span class="string">"\\026\\n\\017grid_dim_height\\022\\003int\\n\\250\\001\\n\\016PsRoiAlignGrad\\022\\013\\n\\006inputs\\"</span>\\<span class="number">001</span>T\\<span class="number">022</span>\\t\\n\\<span class="number">004</span>rois\\<span class="string">"\\001T\\022\\031\\n\\024pooled_features_grad\\"</span>\\<span class="number">001</span>T\\<span class="number">022</span>\\<span class="number">020</span>\\n\\<span class="number">014</span>pooled_index\\<span class="number">030</span>\\<span class="number">003</span>\\<span class="number">032</span>\\<span class="number">020</span>\\n\\<span class="number">013</span>grad_output\\<span class="string">"\\001T\\"</span>\\<span class="number">020</span>\\n\\<span class="number">001</span>T\\<span class="number">022</span>\\<span class="number">004</span>type:\\<span class="number">005</span>\\n\\<span class="number">0032</span>\\<span class="number">001</span>\\<span class="number">001</span>\\<span class="string">"\\025\\n\\016grid_dim_width\\022\\003int\\"</span>\\<span class="number">026</span>\\n\\<span class="number">017</span>grid_dim_height\\<span class="number">022</span>\\<span class="number">003</span>int<span class="string">")</span></div></pre></td></tr></table></figure></p>

        </div>

        <blockquote class="post-copyright">
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2018-03-02T03:47:53.096Z" itemprop="dateUpdated">2018-03-02 11:47:53</time>
</span><br>


        
        原创文章，原文地址：<a href="/2018/03/02/how-new-op-works/" target="_blank" rel="external">https://hikapok.github.io/2018/03/02/how-new-op-works/</a>
        
    </div>
    <footer>
        <a href="https://hikapok.github.io">
            <img src="/img/head_logo.jpg" alt="Kapok">
            Kapok
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/C/">C++</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://hikapok.github.io/2018/03/02/how-new-op-works/&title=《Tensorflow是如何注册和调用C++ New Op的》 — Post Modern Paradigm&pic=https://hikapok.github.io/img/head_logo.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://hikapok.github.io/2018/03/02/how-new-op-works/&title=《Tensorflow是如何注册和调用C++ New Op的》 — Post Modern Paradigm&source=C++、机器学习、计算机视觉" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://hikapok.github.io/2018/03/02/how-new-op-works/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Tensorflow是如何注册和调用C++ New Op的》 — Post Modern Paradigm&url=https://hikapok.github.io/2018/03/02/how-new-op-works/&via=https://hikapok.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://hikapok.github.io/2018/03/02/how-new-op-works/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between flex-row-reverse">
  

  
    <div class="waves-block waves-effect next">
      <a href="/2018/03/01/write-cpp-op/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">使用Tensorflow C++ API自定义操作</h4>
      </a>
    </div>
  
</nav>



    


<section class="comments" id="comments">
    <div id="disqus_thread"></div>
    <script>
    var disqus_shortname = 'kapok';
    lazyScripts.push('//' + disqus_shortname + '.disqus.com/embed.js')
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>










</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        您的鼓励是作者最大的动力，谢谢打赏~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.png" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="/img/wechat.png" data-alipay="/img/alipay.png">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>Kapok &copy; 2018</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://hikapok.github.io/2018/03/02/how-new-op-works/&title=《Tensorflow是如何注册和调用C++ New Op的》 — Post Modern Paradigm&pic=https://hikapok.github.io/img/head_logo.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://hikapok.github.io/2018/03/02/how-new-op-works/&title=《Tensorflow是如何注册和调用C++ New Op的》 — Post Modern Paradigm&source=C++、机器学习、计算机视觉" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://hikapok.github.io/2018/03/02/how-new-op-works/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Tensorflow是如何注册和调用C++ New Op的》 — Post Modern Paradigm&url=https://hikapok.github.io/2018/03/02/how-new-op-works/&via=https://hikapok.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://hikapok.github.io/2018/03/02/how-new-op-works/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACMklEQVR42u3awW7rMAwEwPz/T6eXd3iH2tkVnQKWx6fAcSSNC7Aiqdcrvt7/XUd3jp5PnknGvODCwMC4LeN9ep0/szbX+f1k3l/GwcDAeAAjH7r9VR58k3kP72NgYGCchtc8BCfLxcDAwJgz2tCZJ7EYGBgY54wkiW1LcpNk9Yu5OAYGxg0ZbZnsLz9/pb+BgYFxK8a7vPJx8s3fZD3/xsHAwNiaMdn2tUtsWwj1NhQDA+MxjGRZ3wjT7av5UDXEwMDYlJGU2M6fyb9dA3x4HgMD42GM86DZhsV8zKhVOSm6YWBg3JYx+dkkjObBOtkBYmBg7MqYNBTn/dI2ZNdZOAYGxhaMZMOXT58H37Y8V7xiDAyMTRntQYo2xV0LrHnLEwMDY29GEjrXktW1xmdegPvwd8DAwNiOsTb9tQe82pbDay3GY2Bg3JAx2Zy1Tc08lCcbysPVYmBgPIZx7dU2A0ZxFQMDYztGHuwmLcb5UYzosAUGBsamjGQpCbV9HefzLo6MgYHxGEaeyk6Sz/nnw8MWGBgYD2AkwbRtZCZbvfYFXfB/AwMD4+aM9ghp26qcF9qigIuBgbEFY63Evxag88JZnRJjYGBszZh0PtvmQb6UPKGtYRgYGLdl5EG2bVteVc6r3zQGBsamjCLrjQ9V5Mcp8uV+2OdiYGBglK2CSXGtpmJgYGCUjHmRrg7lGBgYD2Dki8inaVuk7ZEyDAyM5zBGJzXKYllbdLu4qYmBgXE/xg9W97JQuR4P3gAAAABJRU5ErkJggg==" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


lazyScripts.push('//s95.cnzz.com/z_stat.php?id=1264694933&web_id=1264694933')

</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'Kapok的技术博客 | C++、机器学习、计算机视觉';
            clearTimeout(titleTime);
        } else {
            document.title = 'Post Modern Paradigm | 欢迎回来';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



</body>
</html>
