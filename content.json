{"meta":{"title":"Post Modern Paradigm","subtitle":"Kapok的技术博客","description":"C++、机器学习、计算机视觉","author":"Kapok","url":"https://hikapok.github.io"},"pages":[{"title":"Post Modern Paradigm","date":"2017-10-14T15:38:37.000Z","updated":"2017-10-15T15:44:34.000Z","comments":true,"path":"about/index.html","permalink":"https://hikapok.github.io/about/index.html","excerpt":"","text":""},{"title":"","date":"2018-01-19T08:09:55.338Z","updated":"2017-10-11T04:34:12.000Z","comments":false,"path":"tags/index.html","permalink":"https://hikapok.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2018-01-19T08:09:21.831Z","updated":"2017-10-11T04:34:56.000Z","comments":false,"path":"categories/index.html","permalink":"https://hikapok.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"手把手教你用Google云平台搭建自己的深度学习工作站","slug":"intro-to-google-cloud","date":"2018-01-19T08:11:40.000Z","updated":"2018-01-19T11:00:06.214Z","comments":true,"path":"2018/01/19/intro-to-google-cloud/","link":"","permalink":"https://hikapok.github.io/2018/01/19/intro-to-google-cloud/","excerpt":"","text":"Hello，大家好，最近正式启用了自己的博客，一直以来被各种任务缠身，始终没有养成记录自己学习的点滴的习惯。最近忙于申请实习拿到了两个还不错的offer，但无奈导师坚决不放人，于是打算接下来做一些别的事情，输出一些质量高的博文就是其中一项。 自己也算是入行计算机挺久了，一路走来有许多的感慨，包括个人的选择成长规划等等，过段时间也会进行一下总结分享给大家，希望大家能少走弯路。 第一篇博文专注于利用较少的资金建立一个可以用于深度学习调试的小工作站，从整体上来看谷歌云（Google Cloud Platform，GCP）在这价格、稳定性等方面有很大的优势，但是好像并没有多少介绍这方面的文章，作为新手来讲熟悉这些配置可能要花上一两天，这篇博文目的就是让新手在半小时内配置一个可用的深度学习环境，涉及配置的各种细节以及开发过程的各个方面，欢迎大家一起交流讨论。 原材料准备： 支持VISA双币支付的信用卡一张 科学上网工具 PuTTY或其他终端工具 FileZilla或其他支持SFTP的客户端 注册首先你需要有一个Google账户，然后登陆https://cloud.google.com/点击免费试用进行注册，填写基本信息和相关协议，账户类型选择个人，地址注意与信用卡账单地址一致，注册完成后信用卡账户会被预扣1美元，过会就会返还回来的。 创建项目GCP对资源进行层次化的管理，方便结合Cloud Identity and Access Management (IAM)进行权限控制和统一配置，大到公司部门，小到具体某个虚拟机。对于个人用户来说，我们通常只需按照项目来组织我们的资源，项目可以说是我们创建、管理和监控资源、进行权限管理以及账单管理的基本单位了，新建账户默认包含一个初始项目，你也可以在控制台创建自己的新项目（个人用户默认最多10个项目），假设现在你已经配置好了自己的项目。 GCP有很多产品，包括大数据平台，存储和数据库服务，AI相关的API等，来帮助企业更快地创建优质的应用，但这些与本文无关，本文集中介绍如何利用Compute Engine Virtual Machines (VMs)来创建一个较为廉价的可供日常学习使用的机器学习/深度学习平台，合理利用这些资源可以让你尽可能少地为高昂的显卡资源自掏腰包。在正式开始之前有以下几点需要说明一下： 快捷入口：控制台左侧的Tab提供了GCP产品的一些快捷入口，本文主要涉及计算（Compute Engine）、网络（VPC网络）、产品（结算、IAM和管理）和存储（存储），可以先将这些入口钉一下固定在最上面方便一会直接点进去。 预算：作为穷学生一枚本人比较关心钱的问题，虽然有Google赠送的300美元的现金券，我还是一开始就为整个项目（或者以整个计算账号为单位）制定了预算，超出时会自动提醒。费用是每天更新一次，结算周期是半个月，Google会在你花超过100美元或者距上次缴费超过一个月后自动扣款，费用详情可以在结算/交易里查询。 配额：由于每个账号所拥有的资源都有一定的配额，并且GCP默认的GPU配额是0，因此我们需要进行配额调整的申请。具体在IAM和管理/配额里面操作，见图，点击指标下拉框搜索NVIDIA就会看到K80、P100等型号的GPU，把其他资源都反选掉，只保留GPU相关的服务。然后在下面列表里勾选你要选用的GPU型号（注意区域要和待会要创建的VMs所在区域一致），型号根据自己情况进行选择，本人选了K80（12GB内存可以满足我的日常使用），然后选择最上面的修改配额，在右侧弹窗里输入个人电话，目标调整数量以及申请理由，提交即可，我大概等了不到10分钟就调整好了。 创建虚拟机创建VMs相关的操作都在Compute Engine菜单下，为了节省费用同时不至于太影响训练速度，我只设置了30GB的永久固态硬盘，然后又创建了120GB的永久机械硬盘挂载到实例上。如果你只希望用固态硬盘当做启动盘和数据盘，可以忽略创建磁盘这一步。 创建磁盘Compute Engine/磁盘：点击最上面创建磁盘，输入名称，选择与VMs一致的地区，类型设置为标准永久性磁盘，土豪可以选择SSD永久性磁盘，由于初次使用没有映像或者快照，因此来源类型选无（空白磁盘），待会我们在VMs里面进行格式化和分区操作。大小根据自己需求，建议可以稍大一些，一方面性能会好一些，另一方面各种数据集通常都要来回捣腾，因此最好要比预期数据量大一倍。 创建VMsCompute Engine/VM实例：点创建，输入名称，这个名称会作为计算机名，选择与GPU和磁盘一致的区域，机器类型勾选自定义，我选的是4vCPU、8GB内存、1个K80 GPU，详单见图。启动磁盘选更改进行配置，选择Ubuntu 16.04 LTS操作系统镜像，如果我们之前对自己创建的虚拟机备份过映像这里可以直接选上，启动磁盘类型建议选择SSD大小自己配置，如果你之前有删除实例后剩下的启动磁盘想直接用可以在现有磁盘下面勾选，前提是里面要有操作系统。 防火墙一栏勾上允许HTTP流量和HTTPS流量。下方磁盘那个Tab可以设置是否在删除实例时也把启动盘删除，这里我们在额外磁盘下面选择添加一项把之前创建的数据磁盘挂上来。管理Tab里面可以设置启动脚本，方便每次开机时进行系统更新、外部磁盘挂载等操作，这里我先没有设置，因为后面可以在弄好机器后在更改元数据里面重新设置。此外如果你不需要长时间训练模型那么可以开启抢占式VM，缺点就是随时都可能被终止（大约10%~20%的概率，实际由对应区域用量决定），即使由于整个区域用量较小没有被停掉24小时之后也会被终止，如果刚开启虚拟机10分钟之内被抢占是不收费的，需要注意的是抢占式VM的资源总量是有限的，也就是说并不是什么时候想用什么时候就有。 SSH密钥那个Tab里面我们需要配置一下以便使用其它终端工具对VM进行操作，GCP也自带基于浏览器的一种终端，感觉也不错，但是比较慢。终端工具根据自己习惯选择，这里以PuTTY为例进行配置。PuTTY带有一个密钥生成工具PuTTYgen，打开界面如下： 点击generate然后在空白区域来回晃几下鼠标就会生成一个ssh-rsa密钥，comment改成自己的用户名，VM会自动创建对应的账户，然后复制Public key（就是以ssh-rsa开头的最长的那个）粘贴到GCP刚才那个Tab里面，点创建等几分钟即可。接下来我们需要把刚才生成的密钥保存在同一个目录，保存private key的时候会提示设置密码。保存完毕后需要打开PuTTY新建一个session，这会VM实例应该也创建完毕，把外部ip地址填进来，然后在Connection-&gt;SSH-&gt;Auth属性页最下面把保存的private key加载进来，最后打开连接，安全提示选是然后就可以连接到虚拟机了。 如果你想直接用在线的SSH的话，直接在Compute Engine/VM实例里面点SSH，可以通过这个工具上传下载一些简单的文件之类的。 设置数据磁盘 数据磁盘本身是空白磁盘，虽然被接进来了，但必须进行格式化分区之后才可以挂载。以下命令帮你查看数据磁盘是不是真的连接进来了，并查看对应的设备号，我这里是sdb。 1sudo fdisk –l 接下来我们需要对空白磁盘进行分区，同样是使用fdisk命令进入一个交互式的环境，这个环境下所有的操作都不会立刻写进分区表，除非显式地通过w保存操作： 1sudo fdisk /dev/sdb 根据相应的快捷键提示可以很容易完成分区，我的整个磁盘只有一个分区，如果你的磁盘很大也可以分多个区，n新建分区，d删除分区，w保存分区表，q不保存直接退出。 如果你也是只分了一个区，那么你应该会得到一个名为sdb1的新设备，下面命令完成格式化，你也可以换成ntfs格式，这里使用linux格式： 1sudo mkfs.ext4 /dev/sdb1 接下来我们在/media目录下新建一个挂载点（我这里名称为disk），把刚才格式化好的设备挂载进来： 12sudo mkdir /media/disksudo mount /dev/sdb1 /media/disk 如果你不想每次开机都手动挂载这个设备的话，可以设置上面说到的那个启动脚本，启动脚本的设置需要在关机状态下进行，待会你重启时记得设置：仍然是在Compute Engine/VM实例下面，点击VM的名称进入VM详情页面，点击最上面修改，往下拉找到自定义元数据，键设为startup-script，值设置为下面的脚本内容，然后点保存重启虚拟机。 12#! /bin/bashmount /dev/sdb1 /media/disk 同样的方法也可以设置shutdown-script，可以在关机或被抢占时保存模型或给自己发个邮件提醒之类的。 以上步骤完成后，我们还需要设置一下防火墙： 网络/VPC网络/防火墙规则：然后点击最上面创建防火墙规则，名称default-dev之类，目标选网络中的所有实例，来源 IP 地址范围填0.0.0.0/0，协议和端口填tcp:6000-6010;tcp:8888（这个根据日常开发用到的端口自己决定），其他保持默认。 环境配置现在你已经有了一台至少4核8G内存附带一张K80显卡的机器了，接下来就是跟普通机器一样配置环境了。如果你已经很熟悉深度学习之类的环境配置，可以直接跳过这一部分。 我通常先会按照自己的使用习惯配置一下tmux、git和vim，装一些插件之类的。下面的命令可以帮你把一些大概率会用到的包提前装上，以免后续安装过程卡壳： 1sudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev valgrind cmake unrar gfortran python3-pip python3-dev python3-wheel swig git git-core htop 建议日常的机器学习之类的调试训练都在虚拟环境下进行，虚拟环境配置可以参考下面命令： 1234sudo apt-get install python-pip python-setuptoolssudo pip install --upgrade pipsudo pip install virtualenvcurl -L https://raw.github.com/yyuu/pyenv-installer/master/bin/pyenv-installer | bash 设置虚拟环境对应的环境变量 1sudo vim ~/.bash_profile 在文件最后加上下面这些内容： 123export PATH=\"/home/yourname/.pyenv/bin:$PATH\"eval \"$(pyenv init -)\"eval \"$(pyenv virtualenv-init -)\" 生效更改然后安装python 3.5.2： 12source ~/.bash_profilepyenv install 3.5.2 注意把默认的python设置为系统对应的python版本 1234# 查看可用的python版本，注意默认版本pyenv versions# 把默认版本设为系统自带的python版本pyenv global system 在当前目录下创建一个名为pyenv35的虚拟环境 1virtualenv -p .pyenv/versions/3.5.2/bin/python3.5 pyenv35 激活刚创建的虚拟环境 1source pyenv35/bin/activate 安装常用机器学习包（这个根据自己的需求来） 1pyenv35/bin/pip3.5 install numpy scipy matplotlib pandas seaborn sklearn lightgbm xgboost tqdm 安装CUDA运行时环境 首先确认一下系统应该至少没有安装除nvidia-common之外的任何nvidia的包： 1dpkg -l | grep -i nvidia 否则使用以下命令删除多余的包及配置文件： 12sudo apt-get remove --purge name_of_ packagesudo apt-get autoremove 然后我们需要下载CUDA的安装包和cuDNN： 123sudo wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.debsudo wget http://developer.download.nvidia.com/compute/redist/cudnn/v6.0/cudnn-8.0-linux-x64-v6.0.tgzsudo wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/patches/2/cuda-repo-ubuntu1604-8-0-local-cublas-performance-update_8.0.61-1_amd64-deb 接下来安装驱动和运行时： 123sudo dpkg -i cuda-repo-ubuntu1604_8.0.61-1_amd64.debsudo dpkg -i cuda-repo-ubuntu1604-8-0-local-cublas-performance-update_8.0.61-1_amd64.debsudo apt-get update 查看可用的CUDA运行时版本： 1sudo apt-cache policy cuda 安装CUDA8.0 1sudo apt-get install cuda=8.0.61-1 添加源并更新到最新驱动： 1sudo add-apt-repository ppa:graphics-drivers/ppa 这里记得需要敲回车键确认添加源 123sudo apt-get updatesudo apt-get upgradesudo reboot 安装cuDNN 1234tar -xvf cudnn-8.0-linux-x64-v6.0.tgzsudo cp cuda/include/cudnn.h /usr/local/cuda/includesudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* 设置环境变量： 1sudo vim ~/.bashrc 在文件最后添加下面内容： 123export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\"export CUDA_HOME=/usr/local/cudaexport PATH=\"$CUDA_HOME/bin:$PATH\" 生效更改 1source ~/.bashrc 最后敲nvidia-smi确认驱动安装成功 安装深度学习工具包安装bazel、tensorflow-gpu、PyTorch、MxNet 1234sudo apt-get install openjdk-8-jdkecho \"deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8\" | sudo tee /etc/apt/sources.list.d/bazel.listcurl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -sudo apt-get update &amp;&amp; sudo apt-get install bazel 先进入虚拟环境，然后执行以下命令安装： 1pyenv35/bin/pip3.5 install opencv-python tensorflow-gpu http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp35-cp35m-linux_x86_64.whl torchvision mxnet-cu80==1.0.0 配置远程jupyter notebook 仍然是在虚拟环境下，安装notebook: 1pyenv35/bin/pip3.5 install jupyter notebook 进入python交互式环境，生成hash密码： 12from notebook.auth import passwdpasswd() 输入密码并记下形如’sha1:daa96*06c24059c807b08’的字串。 在bash里输入下面的命令生成notebook配置文件 1jupyter notebook --generate-config 编辑配置文件，设置密码和权限等： 1sudo vim .jupyter/jupyter_notebook_config.py 设置以下几项并保存： 1234c.NotebookApp.ip = '*'c.NotebookApp.password = u'sha1:daa96*06c24059c807b08'c.NotebookApp.open_browser = Falsec.NotebookApp.port = 8888 执行jupyter notebook打开notebook，然后在本地浏览器打开http://yourip:8888，如果正常的话，输入密码就可以使用了。如果有问题可以确认一下防火墙。 现在是时候去网上找一些测试代码来确认安装过程的正确性了。 文件共享本想按照往常一样安装samba将虚拟机的磁盘映射到windows系统网络驱动器来传文件，但是搞了半天老是连不通，有知道解决方案的知友欢迎留言。因此目前只能采用FileZilla通过SFTP给VMs传文件的方式。操作如下： 打开FileZilla-&gt;文件-&gt;站点管理器-&gt;新站点：主机填VM的外部ip，协议选择SFTP，登录类型选择密码文件，然后把之前用PuTTY生成的私钥加载进来，高级选项卡里面可以设置本地目录和远程目录。最后点连接就行了，如果有问题的话可以检查一下远程目录的权限，我试了一下传输速度还挺快。 还有一点，日常的开发工作除了用notebook远程连接外，还可以在SublimeText下面使用SFTP的插件，配置过程跟上面文件传输的配置类似。 好了现在就应该都大功告成了，最后别忘了为配置好的系统制作映像，以便将来重新安装： Compute Engine-&gt;映像-&gt;创建映像。 最近会抽空更新几篇机器学习相关的文章，欢迎大家关注，也欢迎大家讨论交流、指出问题。","categories":[{"name":"其它","slug":"others","permalink":"https://hikapok.github.io/categories/others/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://hikapok.github.io/tags/机器学习/"},{"name":"深度学习","slug":"深度学习","permalink":"https://hikapok.github.io/tags/深度学习/"},{"name":"环境配置","slug":"环境配置","permalink":"https://hikapok.github.io/tags/环境配置/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-10-16T08:42:43.371Z","updated":"2017-10-02T15:52:19.000Z","comments":true,"path":"2017/10/16/hello-world/","link":"","permalink":"https://hikapok.github.io/2017/10/16/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}