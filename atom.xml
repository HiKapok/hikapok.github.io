<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Post Modern Paradigm</title>
  <icon>https://www.gravatar.com/avatar/633928e79a33db14690af625e0513ee6</icon>
  <subtitle>Kapok的技术博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://hikapok.github.io/"/>
  <updated>2018-03-02T06:39:07.884Z</updated>
  <id>https://hikapok.github.io/</id>
  
  <author>
    <name>Kapok</name>
    <email>wangchangan@yeah.net</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Tensorflow是如何注册和调用C++ New Op的</title>
    <link href="https://hikapok.github.io/2018/03/02/how-new-op-works/"/>
    <id>https://hikapok.github.io/2018/03/02/how-new-op-works/</id>
    <published>2018-03-02T02:52:15.000Z</published>
    <updated>2018-03-02T06:39:07.884Z</updated>
    
    <content type="html"><![CDATA[<p>寒假回来想起来挖的坑，但好像并没有特别好的主题可以写，更不用说实习招聘近在眼前了，于是打算先扩展一下之前在知乎上的两个回答。</p><p>本文主要介绍动态链接的C++ New Op是如何被注册进来，又如何被Python代码调用的，也算是给自己的一个交代，毕竟本人一直不太喜欢high-level的API。本文大致分为三个模块：注册Ops，注册Kernel，调用Ops。</p><h1 id="Ops的注册过程"><a href="#Ops的注册过程" class="headerlink" title="Ops的注册过程"></a><strong>Ops的注册过程</strong></h1><p>先说一下OpRegistrationData这个东西，这个类的对象由全局注册器Registry负责分配，作用简单来说就是保存OpDef和OpShapeInferenceFn函数，前者保存有Op的各种具体信息，会由OpDefBuilder在最后的解析参数时（成员函数Finalize）放进来，后者在SetShapeFn传进来（由Wrapper转发），所谓注册就是将op name和OpRegistrationData关联起来，具体来说放进hashmap。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">mutable</span> <span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>, <span class="keyword">const</span> OpRegistrationData*&gt; registry_;</div></pre></td></tr></table></figure></p><p>还得先说一下OpDefBuilder这个类，OpDefBuilder会负责接收Op的各种属性和参数定义（就是REGISTER_OP时指定的，见下），最后统一解析（注意只是解析并不保证合法性之类的）并转给OpRegistrationData这个类（包括ShapeFn）。</p><p>我们自己注册op都会通过下面这个宏定义：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">REGISTER_OP(<span class="string">"YourOp"</span>)</div><div class="line">   .Attr(<span class="string">"T: &#123;float&#125;"</span>)</div><div class="line">   .Input(<span class="string">"logits: T"</span>)</div><div class="line">   .Input(<span class="string">"Labels: T"</span>)</div><div class="line">   .Output(<span class="string">"loss: T"</span>)</div><div class="line">   .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) &#123;</div><div class="line">     c-&gt;set_output(<span class="number">0</span>, c-&gt;MakeShape(&#123;<span class="number">1</span>&#125;));</div><div class="line">     <span class="keyword">return</span> Status::OK();</div><div class="line">   &#125;);</div></pre></td></tr></table></figure></p><p>细节都在REGISTER_OP那个宏定义里面，简化如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">static OpDefBuilderReceiver register_op = OpDefBuilderWrapper('YourOp')</div></pre></td></tr></table></figure></p><p>其中OpDefBuilderWrapper内部保存有一个OpDefBuilder成员变量，你所有对REGISTER_OP宏连续调用的操作包括op的名字最后都会一股脑转发给前面那个唯一的OpDefBuilder变量，而OpDefBuilderReceiver则拿过来BuilderWrapper交给一个负责管理所有Op注册的Registry，Registry暴露Register方法给op们注册，把官方的example摘过来示意一下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//Example registration:</span></div><div class="line">  OpRegistry::Global()-&gt;Register(</div><div class="line">    [](OpRegistrationData* op_reg_data)-&gt;Status &#123;</div><div class="line">      <span class="comment">// Populate *op_reg_data here.</span></div><div class="line">      <span class="keyword">return</span> Status::OK();</div><div class="line">  &#125;);</div></pre></td></tr></table></figure></p><p>（先解释下：OpRegistry::Global()简单的单例模式，返回OpRegistry的全局唯一实例，当然这里必须要感谢下新标准对static线程安全的保证。）</p><p>在那个lambda里面你就可以做任何想做的事情了，比如就像OpDefBuilderReceiver一样把BuilderWrapper拿进来，然后把wrapper去掉取出OpDefBuilder，看到上面lambda里面那个op_reg_data没，对这就是之前提到的将解析好参数及shapefn传到OpRegistrationData里，最后Register拿到op的name和OpRegistrationData组成pair放进hashmap完成注册，同时会做一些合法性检查的事情。如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">OpRegistry::Global()-&gt;Register(</div><div class="line">      [wrapper](OpRegistrationData* op_reg_data) -&gt; Status &#123;</div><div class="line">        <span class="keyword">return</span> wrapper.builder().Finalize(op_reg_data);</div><div class="line">      &#125;);</div></pre></td></tr></table></figure></p><p>其实到这里真正的注册并不一定会发生，下面会详细说。</p><h1 id="Kernel的注册过程"><a href="#Kernel的注册过程" class="headerlink" title="Kernel的注册过程"></a><strong>Kernel的注册过程</strong></h1><p>与Ops的注册类似，也是有一个叫作KernelDefBuilder的wrapper，内部保存有KernelDef的一个指针，用于设置各种属性，最后调用Build函数可返回该指针并清空Builder，Kernel的注册主要是通过下面这个宏来实现的：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">REGISTER_KERNEL_BUILDER(                                       \</div><div class="line">      Name(<span class="string">"PsRoiAlignGrad"</span>).Device(DEVICE_GPU).TypeConstraint&lt;<span class="keyword">float</span>&gt;(<span class="string">"T"</span>), \</div><div class="line">      PSROIAlignGradOp&lt;GPUDevice, <span class="keyword">float</span>&gt;);</div></pre></td></tr></table></figure></p><p>其中Name是KernelDefBuilder的一个派生类，Name(“KernelName”)会首先创建一个KernelDefBuilder同时设置设置kernel名称，每次调用这种setter函数就会返回Builder自身从而支持连续调用，然后是设置Device，最后添加值float到属性T中。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Name</span> :</span> <span class="keyword">public</span> KernelDefBuilder &#123;</div><div class="line"> <span class="keyword">public</span>:</div><div class="line">  <span class="comment">// For system kernels, we ignore selective registration and</span></div><div class="line">  <span class="comment">// unconditionally register the kernel.</span></div><div class="line">  explicit Name(const char* op) : KernelDefBuilder(op) &#123;&#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure><p>REGISTER_KERNEL_BUILDER宏里面就是一些trick，实质是创建一个名称唯一的类型为OpKernelRegistrar的全局静态变量，如果你有兴趣可以看一下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">define</span> REGISTER_KERNEL_BUILDER(kernel_builder, ...) \</span></div><div class="line">  REGISTER_KERNEL_BUILDER_UNIQ_HELPER(__COUNTER__, kernel_builder, __VA_ARGS__)</div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> REGISTER_KERNEL_BUILDER_UNIQ_HELPER(ctr, kernel_builder, ...) \</span></div><div class="line">  REGISTER_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, __VA_ARGS__)</div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> REGISTER_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, ...)        \</span></div><div class="line">  <span class="keyword">constexpr</span> <span class="keyword">bool</span> should_register_#<span class="meta">#ctr##__flag =                      \</span></div><div class="line">      SHOULD_REGISTER_OP_KERNEL(#__VA_ARGS__);                        \</div><div class="line">  <span class="keyword">static</span> ::tensorflow::kernel_factory::OpKernelRegistrar              \</div><div class="line">      registrar__body__#<span class="meta">#ctr##__object(                               \</span></div><div class="line">          should_register_#<span class="meta">#ctr##__flag                               \</span></div><div class="line">              ? ::tensorflow::register_kernel::kernel_builder.Build() \</div><div class="line">              : <span class="literal">nullptr</span>,                                              \</div><div class="line">          #__VA_ARGS__,                                               \</div><div class="line">          [](::tensorflow::OpKernelConstruction* context)             \</div><div class="line">              -&gt; ::tensorflow::OpKernel* &#123;                            \</div><div class="line">            <span class="keyword">return</span> <span class="keyword">new</span> __VA_ARGS__(context);                          \</div><div class="line">          &#125;);</div></pre></td></tr></table></figure><p>OpKernelRegistrar静态变量的构造需要三个参数，如下所示，第一个是KernelDef，第二个是定义Kernel的类名，第三个是创建kernel对象的函数，其实后面就可以知道这三个参数都会被包装到KernelRegistration这个结构体里，然后作为Kernel注册表的值。因此这个宏会首先调用KernelDefBuilder的Build函数获得对应的KernelDef；然后获取用于创建这个Kernel的C++类名称（这个类是继承自OpKernel的）；最后包装一个factory函数用来接收传进来的OpKernelConstruction*，创建对应的Kernel类对象，并返回其指针。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpKernelRegistrar</span> &#123;</span></div><div class="line"> <span class="keyword">public</span>:</div><div class="line">  <span class="keyword">typedef</span> OpKernel* (*Factory)(OpKernelConstruction*);</div><div class="line"></div><div class="line">  OpKernelRegistrar(<span class="keyword">const</span> KernelDef* kernel_def, StringPiece kernel_class_name,</div><div class="line">                    Factory factory) &#123;</div><div class="line">    <span class="keyword">if</span> (kernel_def != <span class="literal">nullptr</span>) &#123;</div><div class="line">      InitInternal(kernel_def, kernel_class_name, factory);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><p>这里是<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/framework/op_kernel.cc#L909" target="_blank" rel="external">InitInternal</a>的细节<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> OpKernelRegistrar::InitInternal(<span class="keyword">const</span> KernelDef* kernel_def,</div><div class="line">                                     StringPiece kernel_class_name,</div><div class="line">                                     Factory factory) &#123;</div><div class="line">  <span class="comment">// See comments in register_kernel::Name in header for info on _no_register.</span></div><div class="line">  <span class="keyword">if</span> (kernel_def-&gt;op() != <span class="string">"_no_register"</span>) &#123;</div><div class="line">    <span class="keyword">const</span> <span class="built_in">string</span> key =</div><div class="line">        Key(kernel_def-&gt;op(), DeviceType(kernel_def-&gt;device_type()),</div><div class="line">            kernel_def-&gt;label());</div><div class="line">    GlobalKernelRegistryTyped()-&gt;insert(<span class="built_in">std</span>::make_pair(</div><div class="line">        key, KernelRegistration(*kernel_def, kernel_class_name, factory)));</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">delete</span> kernel_def;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>可以看到OpKernelRegistrar这个类主要是负责根据传进来的KernelDef和KernelFactory，首先依据一定规则生成一个适当的key，并插入到一个全局唯一的Kernel注册表里，注册表当然是一个map但是值得注意的是它是multimap因此支持一个键对应多个kernel副本。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="built_in">std</span>::<span class="built_in">unordered_multimap</span>&lt;<span class="built_in">string</span>, KernelRegistration&gt; KernelRegistry;</div></pre></td></tr></table></figure></p><h1 id="OpKernel的创建与调用"><a href="#OpKernel的创建与调用" class="headerlink" title="OpKernel的创建与调用"></a><strong>OpKernel的创建与调用</strong></h1><p>如果你还记得的话，前面还有一个全局的OpRegistry，这样根据NodeDef里的Op名称就可以获得Op对应的信息，再结合设备类型也就可以获得Kernel对应的信息了，而NodeDef是在Python创建Operation之前创建的，可以看这里<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/ops.py#L3086" target="_blank" rel="external">create_op</a>，后面会提到调用这个函数的地方。</p><p>然后就可以根据一个NodeDef和当前的设备类型在运行时创建一个OpKernel了，每个被创建的OpKernel都会被自动地管理生命周期。在<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/device.h#L165" target="_blank" rel="external">Device</a>类中会有一个OpSegment对象，<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/framework/op_segment.h#L31" target="_blank" rel="external">OpSegment</a>会管理一个sessions中用到的kernel，根据情况来决定是创建新的还是复用之前的OpKernel，具体来说是有两个嵌套的hashmap，第一个将session handle映射到一个KernelMap，然后在KernelMap就可以去查找是否有对应Op名的OpKernel，如果没有就调用一个create_fn函数进行创建。</p><p>那么问题来了，这背后的原动力在哪？事实上Session在第一次为某个Node创建Executor的时候这一切就发生了（后面会再说到Executor的）：<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/direct_session.cc#L1064" target="_blank" rel="external">DirectSession::GetOrCreateExecutors</a>，更直接地可以看查找失败后第一次创建Executor的<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/direct_session.cc#L1202" target="_blank" rel="external">地方</a>，代码片段如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">LocalExecutorParams params;</div><div class="line">params.device = device;</div><div class="line">params.function_library = lib;</div><div class="line"><span class="keyword">auto</span> opseg = device-&gt;op_segment();</div><div class="line">params.create_kernel = [<span class="keyword">this</span>, lib, opseg](<span class="keyword">const</span> NodeDef&amp; ndef, OpKernel** kernel) &#123;</div><div class="line">  <span class="comment">// We do not share the kernel via the OpSegment if the node is</span></div><div class="line">  <span class="comment">// stateless, or a function.</span></div><div class="line">  <span class="comment">// NOTE(mrry): We must not share function kernels (implemented</span></div><div class="line">  <span class="comment">// using `CallOp`) between subgraphs, because `CallOp::handle_`</span></div><div class="line">  <span class="comment">// is tied to a particular subgraph. Even if the function itself</span></div><div class="line">  <span class="comment">// is stateful, the `CallOp` that invokes it is not.</span></div><div class="line">  <span class="keyword">if</span> (!lib-&gt;IsStateful(ndef.op()) ||</div><div class="line">  lib-&gt;GetFunctionLibraryDefinition()-&gt;Find(ndef.op()) != <span class="literal">nullptr</span>) &#123;</div><div class="line"><span class="keyword">return</span> lib-&gt;CreateKernel(ndef, kernel);</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">auto</span> create_fn = [lib, &amp;ndef](OpKernel** kernel) &#123;</div><div class="line"><span class="keyword">return</span> lib-&gt;CreateKernel(ndef, kernel);</div><div class="line">  &#125;;</div><div class="line">  <span class="comment">// Kernels created for subgraph nodes need to be cached.  On</span></div><div class="line">  <span class="comment">// cache miss, create_fn() is invoked to create a kernel based</span></div><div class="line">  <span class="comment">// on the function library here + global op registry.</span></div><div class="line">  <span class="keyword">return</span> opseg-&gt;FindOrCreate(session_handle_, ndef.name(), kernel,</div><div class="line"> create_fn);</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><p>可以看到取出OpSegment，构造create_fn并调用FindOrCreate的过程。其中create_fn内部调用的FunctionLibraryRuntime的CreateKernel函数可以看这里：<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/function.cc#L366" target="_blank" rel="external">FunctionLibraryRuntimeImpl::CreateKernel</a>，再往下<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/executor.cc#L2621" target="_blank" rel="external">CreateNonCachedKernel</a>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function">Status <span class="title">CreateNonCachedKernel</span><span class="params">(Device* device, FunctionLibraryRuntime* flib,</span></span></div><div class="line"><span class="function"><span class="params">                             <span class="keyword">const</span> NodeDef&amp; ndef, <span class="keyword">int</span> graph_def_version,</span></span></div><div class="line"><span class="function"><span class="params">                             OpKernel** kernel)</span> </span>&#123;</div><div class="line">  <span class="keyword">const</span> <span class="keyword">auto</span> device_type = DeviceType(device-&gt;attributes().device_type());</div><div class="line">  <span class="keyword">auto</span> allocator = device-&gt;GetAllocator(AllocatorAttributes());</div><div class="line">  <span class="keyword">return</span> CreateOpKernel(device_type, device, allocator, flib, ndef,</div><div class="line">                        graph_def_version, kernel);</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>看到了CreateOpKernel的调用，这下总算回到了我们最开始的地方<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/core/framework/op_kernel.cc#L1059" target="_blank" rel="external">CreateOpKernel</a>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function">Status <span class="title">CreateOpKernel</span><span class="params">(DeviceType device_type, DeviceBase* device,</span></span></div><div class="line"><span class="function"><span class="params">                      Allocator* allocator, FunctionLibraryRuntime* flib,</span></span></div><div class="line"><span class="function"><span class="params">                      <span class="keyword">const</span> NodeDef&amp; node_def, <span class="keyword">int</span> graph_def_version,</span></span></div><div class="line"><span class="function"><span class="params">                      OpKernel** kernel)</span></span></div></pre></td></tr></table></figure><p>这个核心函数主要是做一下以下几件事情：根据node_def取出op名，去查OpRegistry，并与node_def的信息进行校验，比如接口是否一致，node_def中是否包含所有op_def中的信息等，然后根据device_type和op名去查KernelRegistry获取KernelRegistration，就是map中的值，包含之前提到的三项。接着是确定输入输出类型及其存储位置，最后是创建一个OpKernelConstruction对象，并传给Kernel的factory函数函数，这就到了用户自己写的函数这边了：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Everything needed for OpKernel construction.</span></div><div class="line"><span class="function">OpKernelConstruction <span class="title">context</span><span class="params">(</span></span></div><div class="line"><span class="function"><span class="params">  device_type, device, allocator, &amp;node_def, op_def, flib, inputs,</span></span></div><div class="line"><span class="function"><span class="params">  input_memory_types, outputs, output_memory_types, graph_def_version, &amp;s)</span></span>;</div><div class="line">*kernel = (*registration-&gt;factory)(&amp;context);</div></pre></td></tr></table></figure><p>Kernel创建完了，那么它什么时候被执行呢？前面说到第一次创建executor的时候会创建OpKernel，其实每次Session调用Run的时候最终也是转到executor这边来执行的，包括根据当前的运行时环境创建OpKernelContext以及<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/executor.cc#L1656" target="_blank" rel="external">OpKernel::Compute的调用</a>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Synchronous computes.</span></div><div class="line"><span class="function">OpKernelContext <span class="title">ctx</span><span class="params">(&amp;params, item.num_outputs)</span></span>;</div><div class="line">nodestats::SetOpStart(stats);</div><div class="line">device-&gt;Compute(CHECK_NOTNULL(op_kernel), &amp;ctx);</div><div class="line">nodestats::SetOpEnd(stats);</div></pre></td></tr></table></figure><p>其中device-&gt;Compute这一步通过查看基类的实现就大概能知道所有细节了<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/common_runtime/device.h#L82" target="_blank" rel="external">Device::Compute</a>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Performs the actual compute function.</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// Subclasses may override this function if they wish to perform</span></div><div class="line"><span class="comment">// some initialization before each compute.</span></div><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Compute</span><span class="params">(OpKernel* op_kernel, OpKernelContext* context)</span> </span>&#123;</div><div class="line">  op_kernel-&gt;Compute(context);</div><div class="line">&#125;</div></pre></td></tr></table></figure><p>可以发现，我们写的Compute方法在这里就被调用了。至此故事好像可以告一段落了，不过说了半天好像一直在C++这边啊，那Python代码怎么调用的呢？</p><h1 id="注册Ops和Kernel后传"><a href="#注册Ops和Kernel后传" class="headerlink" title="注册Ops和Kernel后传"></a><strong>注册Ops和Kernel后传</strong></h1><p>根据上面REGISTER_KERNEL_BUILDER所展开的两段程序很容易就判断出如果动态库被加载进来的话，Kernel就会自动完成注册，这跟Ops的注册基本是一样的，不同之处在于动态链接进来的Ops会在加载库之前设置延迟注册的标记，并添加一个Watcher，然后手动调用注册，这主要是为了通过Watcher获取注册过程中从OpRegistrationData（就是注册表的值）中取出的OpDef，这一点可以在后面的LoadLibrary中看到。这个过程很重要，通过获得的OpDef组成的OpList并序列化后，Python端就可以解析出这些OpDef，同时调用C++这边利用这些OpDef生成对应的ApiDef，二者结合就可以动态生成定义这个Op的Python代码，然后返回到Python端执行这些代码，注意这些代码的执行并不包括创建Op并添加到Graph这个过程，只包括定义相关代码段的函数，下面是从Python端load_op_library一直到生成Python代码的过程：<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/load_library.py#L73" target="_blank" rel="external">load_op_library</a>-&gt;<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/python_op_gen.cc#L866" target="_blank" rel="external">GetPythonWrappers</a>-&gt;<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/python_op_gen.cc#L776" target="_blank" rel="external">GetPythonOps</a>-&gt;<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/python_op_gen.cc#L770" target="_blank" rel="external">GetPythonOp</a>-&gt;<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/python_op_gen.cc#L478" target="_blank" rel="external">GenPythonOp::Code()</a>。还有从OpList生成ApiDef的地方<a href="https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/core/framework/op_gen_lib.cc#L471" target="_blank" rel="external">ApiDefMap::ApiDefMap(const OpList&amp; op_list)</a>。如果你有兴趣的话可以去看一下我之前写的一个Op自动生成的代码，我附在了本文最后，生成代码中的apply_op就是添加Op到Graph的代码，可以看这里<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/python/framework/op_def_library.py#L294" target="_blank" rel="external">apply_op</a>，这个函数的最后面就是前面提到的调用Graph的create_op。</p><p>下面是LoadLibrary的代码段，可以对照一下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="function">Status <span class="title">LoadLibrary</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* library_filename, <span class="keyword">void</span>** result,</span></span></div><div class="line"><span class="function"><span class="params">                   <span class="keyword">const</span> <span class="keyword">void</span>** buf, <span class="keyword">size_t</span>* len)</span> </span>&#123;</div><div class="line">  <span class="keyword">static</span> mutex mu;</div><div class="line">  <span class="keyword">static</span> <span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>, Library&gt; loaded_libs;</div><div class="line">  Env* env = Env::Default();</div><div class="line">  Library library;</div><div class="line">  <span class="built_in">std</span>::<span class="built_in">unordered_set</span>&lt;<span class="built_in">string</span>&gt; seen_op_names;</div><div class="line">  &#123;</div><div class="line">    <span class="function">mutex_lock <span class="title">lock</span><span class="params">(mu)</span></span>;</div><div class="line">    <span class="keyword">if</span> (loaded_libs.find(library_filename) != loaded_libs.end()) &#123;</div><div class="line">      library = loaded_libs[library_filename];</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">      Status s = OpRegistry::Global()-&gt;ProcessRegistrations();</div><div class="line">      <span class="keyword">if</span> (!s.ok()) &#123;</div><div class="line">        <span class="keyword">return</span> s;</div><div class="line">      &#125;</div><div class="line">      TF_RETURN_IF_ERROR(OpRegistry::Global()-&gt;SetWatcher(</div><div class="line">          [&amp;library, &amp;seen_op_names](<span class="keyword">const</span> Status&amp; s,</div><div class="line">                                     <span class="keyword">const</span> OpDef&amp; opdef) -&gt; Status &#123;</div><div class="line">            <span class="keyword">if</span> (errors::IsAlreadyExists(s)) &#123;</div><div class="line">              <span class="keyword">if</span> (seen_op_names.find(opdef.name()) == seen_op_names.end()) &#123;</div><div class="line">                <span class="comment">// Over writing a registration of an op not in this custom op</span></div><div class="line">                <span class="comment">// library. Treat this as not an error.</span></div><div class="line">                <span class="keyword">return</span> Status::OK();</div><div class="line">              &#125;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span> (s.ok()) &#123;</div><div class="line">              *library.op_list.add_op() = opdef;</div><div class="line">              seen_op_names.insert(opdef.name());</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">return</span> s;</div><div class="line">          &#125;));</div><div class="line">      OpRegistry::Global()-&gt;DeferRegistrations();</div><div class="line">      s = env-&gt;LoadLibrary(library_filename, &amp;library.handle);</div><div class="line">      <span class="keyword">if</span> (s.ok()) &#123;</div><div class="line">        s = OpRegistry::Global()-&gt;ProcessRegistrations();</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">if</span> (!s.ok()) &#123;</div><div class="line">        OpRegistry::Global()-&gt;ClearDeferredRegistrations();</div><div class="line">        TF_RETURN_IF_ERROR(OpRegistry::Global()-&gt;SetWatcher(<span class="literal">nullptr</span>));</div><div class="line">        <span class="keyword">return</span> s;</div><div class="line">      &#125;</div><div class="line">      TF_RETURN_IF_ERROR(OpRegistry::Global()-&gt;SetWatcher(<span class="literal">nullptr</span>));</div><div class="line"></div><div class="line">      loaded_libs[library_filename] = library;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  <span class="built_in">string</span> str;</div><div class="line">  library.op_list.SerializeToString(&amp;str);</div><div class="line">  <span class="keyword">char</span>* str_buf = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">char</span>*&gt;(port::Malloc(str.length()));</div><div class="line">  <span class="built_in">memcpy</span>(str_buf, str.data(), str.length());</div><div class="line">  *buf = str_buf;</div><div class="line">  *len = str.length();</div><div class="line"></div><div class="line">  *result = library.handle;</div><div class="line">  <span class="keyword">return</span> Status::OK();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>自动生成的Python代码，这里是对应的<a href="https://github.com/HiKapok/PSROIAlign" target="_blank" rel="external">C++ Op</a>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div></pre></td><td class="code"><pre><div class="line"><span class="string">"""Python wrappers around TensorFlow ops.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">This file is MACHINE GENERATED! Do not edit.</span></div><div class="line"><span class="string">"""</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> collections <span class="keyword">as</span> _collections</div><div class="line"></div><div class="line"><span class="keyword">from</span> tensorflow.core.framework <span class="keyword">import</span> op_def_pb2 <span class="keyword">as</span> _op_def_pb2</div><div class="line"></div><div class="line"><span class="comment"># Needed to trigger the call to _set_call_cpp_shape_fn.</span></div><div class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> common_shapes <span class="keyword">as</span> _common_shapes</div><div class="line"></div><div class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> op_def_registry <span class="keyword">as</span> _op_def_registry</div><div class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> ops <span class="keyword">as</span> _ops</div><div class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> op_def_library <span class="keyword">as</span> _op_def_library</div><div class="line"><span class="keyword">from</span> tensorflow.python.util.tf_export <span class="keyword">import</span> tf_export</div><div class="line"></div><div class="line">_ps_roi_align_outputs = [<span class="string">"pooled_features"</span>, <span class="string">"pooled_index"</span>]</div><div class="line">_PsRoiAlignOutput = _collections.namedtuple(</div><div class="line">    <span class="string">"PsRoiAlign"</span>, _ps_roi_align_outputs)</div><div class="line"></div><div class="line"></div><div class="line"><span class="meta">@tf_export('ps_roi_align')</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ps_roi_align</span><span class="params">(inputs, rois, grid_dim_width, grid_dim_height, name=None)</span>:</span></div><div class="line">  <span class="string">r"""        PsRoiAlign is a new PsRoiPooling method without align problems.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">          The input rois to be pooled must in format [center_y, center_x, h, w] and each element must be in range [0, 1.].</span></div><div class="line"><span class="string">          The caller must make sure that all rois is valid (has a intersect region (one pixel at least) with the window [0.5, 0.5, 1., 1.]).</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Args:</span></div><div class="line"><span class="string">    inputs: A `Tensor`. Must be one of the following types: `float32`.</span></div><div class="line"><span class="string">    rois: A `Tensor`. Must have the same type as `inputs`.</span></div><div class="line"><span class="string">    grid_dim_width: An `int`.</span></div><div class="line"><span class="string">    grid_dim_height: An `int`.</span></div><div class="line"><span class="string">    name: A name for the operation (optional).</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Returns:</span></div><div class="line"><span class="string">    A tuple of `Tensor` objects (pooled_features, pooled_index).</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    pooled_features: A `Tensor`. Has the same type as `inputs`.</span></div><div class="line"><span class="string">    pooled_index: A `Tensor` of type `int32`.</span></div><div class="line"><span class="string">  """</span></div><div class="line">  _result = _op_def_lib.apply_op(<span class="string">"PsRoiAlign"</span>, inputs=inputs, rois=rois,</div><div class="line">                                 grid_dim_width=grid_dim_width,</div><div class="line">                                 grid_dim_height=grid_dim_height, name=name)</div><div class="line">  _result = _PsRoiAlignOutput._make(_result)</div><div class="line">  <span class="keyword">return</span> _result</div><div class="line"></div><div class="line"></div><div class="line">_ops.RegisterShape(<span class="string">"PsRoiAlign"</span>)(<span class="keyword">None</span>)</div><div class="line"></div><div class="line"><span class="meta">@tf_export('ps_roi_align_grad')</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ps_roi_align_grad</span><span class="params">(inputs, rois, pooled_features_grad, pooled_index, grid_dim_width, grid_dim_height, name=None)</span>:</span></div><div class="line">  <span class="string">r"""        PsRoiAlignGrad is the Gradient op of PsRoiAlign.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">          The input rois to be pooled must in format [center_y, center_x, h, w] and each element must be in range [0, 1.].</span></div><div class="line"><span class="string">          The caller must make sure that all rois is valid (has a intersect region (one pixel at least) with the window [0.5, 0.5, 1., 1.]).</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Args:</span></div><div class="line"><span class="string">    inputs: A `Tensor`. Must be one of the following types: `float32`.</span></div><div class="line"><span class="string">    rois: A `Tensor`. Must have the same type as `inputs`.</span></div><div class="line"><span class="string">    pooled_features_grad: A `Tensor`. Must have the same type as `inputs`.</span></div><div class="line"><span class="string">    pooled_index: A `Tensor` of type `int32`.</span></div><div class="line"><span class="string">    grid_dim_width: An `int`.</span></div><div class="line"><span class="string">    grid_dim_height: An `int`.</span></div><div class="line"><span class="string">    name: A name for the operation (optional).</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Returns:</span></div><div class="line"><span class="string">    A `Tensor`. Has the same type as `inputs`.</span></div><div class="line"><span class="string">  """</span></div><div class="line">  _result = _op_def_lib.apply_op(<span class="string">"PsRoiAlignGrad"</span>, inputs=inputs, rois=rois,</div><div class="line">                                 pooled_features_grad=pooled_features_grad,</div><div class="line">                                 pooled_index=pooled_index,</div><div class="line">                                 grid_dim_width=grid_dim_width,</div><div class="line">                                 grid_dim_height=grid_dim_height, name=name)</div><div class="line">  <span class="keyword">return</span> _result</div><div class="line"></div><div class="line"></div><div class="line">_ops.RegisterShape(<span class="string">"PsRoiAlignGrad"</span>)(<span class="keyword">None</span>)</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_InitOpDefLibrary</span><span class="params">(op_list_proto_bytes)</span>:</span></div><div class="line">  op_list = _op_def_pb2.OpList()</div><div class="line">  op_list.ParseFromString(op_list_proto_bytes)</div><div class="line">  _op_def_registry.register_op_list(op_list)</div><div class="line">  op_def_lib = _op_def_library.OpDefLibrary()</div><div class="line">  op_def_lib.add_op_list(op_list)</div><div class="line">  <span class="keyword">return</span> op_def_lib</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># op &#123;</span></div><div class="line"><span class="comment">#   name: "PsRoiAlign"</span></div><div class="line"><span class="comment">#   input_arg &#123;</span></div><div class="line"><span class="comment">#     name: "inputs"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   input_arg &#123;</span></div><div class="line"><span class="comment">#     name: "rois"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   output_arg &#123;</span></div><div class="line"><span class="comment">#     name: "pooled_features"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   output_arg &#123;</span></div><div class="line"><span class="comment">#     name: "pooled_index"</span></div><div class="line"><span class="comment">#     type: DT_INT32</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   attr &#123;</span></div><div class="line"><span class="comment">#     name: "T"</span></div><div class="line"><span class="comment">#     type: "type"</span></div><div class="line"><span class="comment">#     allowed_values &#123;</span></div><div class="line"><span class="comment">#       list &#123;</span></div><div class="line"><span class="comment">#         type: DT_FLOAT</span></div><div class="line"><span class="comment">#       &#125;</span></div><div class="line"><span class="comment">#     &#125;</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   attr &#123;</span></div><div class="line"><span class="comment">#     name: "grid_dim_width"</span></div><div class="line"><span class="comment">#     type: "int"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   attr &#123;</span></div><div class="line"><span class="comment">#     name: "grid_dim_height"</span></div><div class="line"><span class="comment">#     type: "int"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment"># &#125;</span></div><div class="line"><span class="comment"># op &#123;</span></div><div class="line"><span class="comment">#   name: "PsRoiAlignGrad"</span></div><div class="line"><span class="comment">#   input_arg &#123;</span></div><div class="line"><span class="comment">#     name: "inputs"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   input_arg &#123;</span></div><div class="line"><span class="comment">#     name: "rois"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   input_arg &#123;</span></div><div class="line"><span class="comment">#     name: "pooled_features_grad"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   input_arg &#123;</span></div><div class="line"><span class="comment">#     name: "pooled_index"</span></div><div class="line"><span class="comment">#     type: DT_INT32</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   output_arg &#123;</span></div><div class="line"><span class="comment">#     name: "grad_output"</span></div><div class="line"><span class="comment">#     type_attr: "T"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   attr &#123;</span></div><div class="line"><span class="comment">#     name: "T"</span></div><div class="line"><span class="comment">#     type: "type"</span></div><div class="line"><span class="comment">#     allowed_values &#123;</span></div><div class="line"><span class="comment">#       list &#123;</span></div><div class="line"><span class="comment">#         type: DT_FLOAT</span></div><div class="line"><span class="comment">#       &#125;</span></div><div class="line"><span class="comment">#     &#125;</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   attr &#123;</span></div><div class="line"><span class="comment">#     name: "grid_dim_width"</span></div><div class="line"><span class="comment">#     type: "int"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment">#   attr &#123;</span></div><div class="line"><span class="comment">#     name: "grid_dim_height"</span></div><div class="line"><span class="comment">#     type: "int"</span></div><div class="line"><span class="comment">#   &#125;</span></div><div class="line"><span class="comment"># &#125;</span></div><div class="line">_op_def_lib = _InitOpDefLibrary(<span class="string">b"\\n\\215\\001\\n\\nPsRoiAlign\\022\\013\\n\\006inputs\\"</span>\\<span class="number">001</span>T\\<span class="number">022</span>\\t\\n\\<span class="number">004</span>rois\\<span class="string">"\\001T\\032\\024\\n\\017pooled_features\\"</span>\\<span class="number">001</span>T\\<span class="number">032</span>\\<span class="number">020</span>\\n\\<span class="number">014</span>pooled_index\\<span class="number">030</span>\\<span class="number">003</span>\\<span class="string">"\\020\\n\\001T\\022\\004type:\\005\\n\\0032\\001\\001\\"</span>\\<span class="number">025</span>\\n\\<span class="number">016</span>grid_dim_width\\<span class="number">022</span>\\<span class="number">003</span>int\\<span class="string">"\\026\\n\\017grid_dim_height\\022\\003int\\n\\250\\001\\n\\016PsRoiAlignGrad\\022\\013\\n\\006inputs\\"</span>\\<span class="number">001</span>T\\<span class="number">022</span>\\t\\n\\<span class="number">004</span>rois\\<span class="string">"\\001T\\022\\031\\n\\024pooled_features_grad\\"</span>\\<span class="number">001</span>T\\<span class="number">022</span>\\<span class="number">020</span>\\n\\<span class="number">014</span>pooled_index\\<span class="number">030</span>\\<span class="number">003</span>\\<span class="number">032</span>\\<span class="number">020</span>\\n\\<span class="number">013</span>grad_output\\<span class="string">"\\001T\\"</span>\\<span class="number">020</span>\\n\\<span class="number">001</span>T\\<span class="number">022</span>\\<span class="number">004</span>type:\\<span class="number">005</span>\\n\\<span class="number">0032</span>\\<span class="number">001</span>\\<span class="number">001</span>\\<span class="string">"\\025\\n\\016grid_dim_width\\022\\003int\\"</span>\\<span class="number">026</span>\\n\\<span class="number">017</span>grid_dim_height\\<span class="number">022</span>\\<span class="number">003</span>int<span class="string">")</span></div></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;寒假回来想起来挖的坑，但好像并没有特别好的主题可以写，更不用说实习招聘近在眼前了，于是打算先扩展一下之前在知乎上的两个回答。&lt;/p&gt;
&lt;p&gt;本文主要介绍动态链接的C++ New Op是如何被注册进来，又如何被Python代码调用的，也算是给自己的一个交代，毕竟本人一直不太喜
      
    
    </summary>
    
      <category term="深度学习" scheme="https://hikapok.github.io/categories/deeplearning/"/>
    
    
      <category term="机器学习" scheme="https://hikapok.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://hikapok.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="C++" scheme="https://hikapok.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>使用Tensorflow C++ API自定义操作</title>
    <link href="https://hikapok.github.io/2018/03/01/write-cpp-op/"/>
    <id>https://hikapok.github.io/2018/03/01/write-cpp-op/</id>
    <published>2018-03-01T02:57:28.000Z</published>
    <updated>2018-03-02T08:36:56.372Z</updated>
    
    <content type="html"><![CDATA[<p>Tensorflow提供了大量的基本操作使得我们能够任意组合来实现我们需要的复杂操作，但有时候我们需要的操作不太容易通过这些基本操作来组合，或者复杂的组合方式带来严重的性能开销，这时我们可能会考虑去使用<a href="https://www.tensorflow.org/api_docs/python/tf/py_func" target="_blank" rel="external">py_func</a>来包装Python函数借助Numpy来实现，但性能方面可能也无法达到满意的程度，更不要说有些操作不适合向量化的写法，这个时候用C++ API来实现自己的一个操作可能会是更好的选择。</p><p>总得来说，我们可以通过静态链接或动态连接的方式来添加我们自定义的操作，前者需要你能成功从源码编译安装Tensorflow（<a href="https://www.tensorflow.org/install/install_sources" target="_blank" rel="external">Installing TensorFlow from Sources</a>），后者只需要安装Tensorflow的Python包即可，不过后者有一个缺点就是可用的C++ API是有限的，如果你需要一些别的接口可能要自己去找相关的头文件然后手动添加进来，如果头文件数目很多这就是一件很头疼的事情了，但优点也是很明显，一是简单，二是不用强制要求使用你操作的人也要从源码编译安装Tensorflow。下面主要以动态链接的添加为例进行叙述，对静态链接添加的方式也会有涉及，二者基本上是一样的。另外，本文主要注重实践部分，如果你需要一些更详细的标准化说明，可以去参考官方的Tutorial：<a href="https://www.tensorflow.org/extend/adding_an_op" target="_blank" rel="external">Adding a New Op</a>，一些比如Ops注册的属性说明以及如何保持Ops属性的后向兼容性等会更加详细。</p><p>另外如果你对Tensorflow注册Ops和Kernel的过程或者它们是如何被Python代码调用的感兴趣，可以阅读我之前写的一篇文章<a href="https://hikapok.github.io/2018/03/02/how-new-op-works/">Tensorflow是如何注册和调用C++ New Op的</a>。如果你想学习一下官方Ops是怎么写的，我推荐从<a href="https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/core/kernels/bias_op.cc" target="_blank" rel="external">Bias_Op</a>来开始学习，因为这个Op写的还是很清晰然后对初学者不会有太多的阻碍，当然也可以参考我最近写的<a href="https://github.com/HiKapok/PSROIAlign" target="_blank" rel="external">PSROIAlign</a>。这里还必须要推荐一个利器SourceInsight简直是阅读这种开源代码的法宝。</p><p>先总结官方给的自定义op的标准流程：注册Op，实现Op，创建python接口，实现Op梯度计算（如果不需要求导也可以直接pass掉，实现可以在python端也可以用py_func去包装其他python函数，也可以再写一个C++ Op来专门计算梯度），测试。</p><h1 id="注册Op"><a href="#注册Op" class="headerlink" title="注册Op"></a><strong>注册Op</strong></h1><p>注册Op相当于是一个声明的过程。Op是tensorflow中非常重要的概念，一个Op接收一个或多个输入张量，然后经过某种运算，产生其他零个或多个tensor，然后这些tensor又可以被其他Op使用。类似于C++中我们定义变量需要知道数据类型，字节数等信息一样，创建一个Op同样需要一些额外信息包括attributes（输入输出类型以及合法取值等，也可以看作是Op的输入但是不同于输入的是属性永远是常量，其值在Op被添加到图中时被设置，并且是一直放在CPU上的）以及输入输出列表，还可以直接加Doc，具体信息是我们在REGISTER_OP时指定的，REGISTER_OP是一个宏，其内部实现是一个wrapper利用了C++中的常用伎俩chaining调用实现，所有你在这添加的信息都会以另一种形式出现在动态生成的Python代码中。有一点需要注意，在C++这边Ops的名称必须是CamelCase类型的，在Python那一边会自动被转换成Python风格的snake_case类型。</p><p>注册这个地方还有一个SetShapeFn需要说一下，主要作用是检查输入的shape并指定输出的shape，当然你也可以在Op的compute里面检查之类，但是这个ShapeFn有一个点是可以让tesorflow不用执行操作就能获取输入输出信息。在ShapeFn里面你可以拿到输入输出的每一个维度的大小（DimensionHandle），或者属性常量的值或者输入常量的值，然后组合成输出的ShapeHandle，最后调用set_output指定对应输出的shape，同时DimensionHandle是可以做四则运算的。一开始我对如何指定输出大小的api也有一些困惑，因为还涉及动态shape，这里推荐仔细阅读<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/core/framework/shape_inference.h#L158" target="_blank" rel="external">InferenceContext</a>这个类，还是推荐用SourceInsight用好搜索和bookmark即可。</p><h1 id="实现Op"><a href="#实现Op" class="headerlink" title="实现Op"></a><strong>实现Op</strong></h1><p>动手之前了解一下C++中的functor、模板及其特化还是很有必要的，对lambda也有了解的话就更好了，如果你对C++不熟的话建议尽量避免使用Eigen，直接把数组取出来用C计算就行，因为tensorflow里面的张量都是按行主序存的（多维的情况就是最外面的那一维变化最快）。</p><p>用C++实现Op有一个固定的套路，遵循这个套路可以避免走弯路，当然这都不是必须的，只要你定义了计算函数并且在kernel的Compute里面调用你的计算即可。初学者可以参考下面这个框架来做：</p><ul><li>定义一个Functor模板类做实际的计算工作</li><li>针对不同设备甚至不同数据类型特化Functor模板类</li><li>定义一个Kernel模板类，继承自OpKernel，在构造函数中根据传进来的OpKernelConstruction设置必要的成员</li><li>视情况针对别的设备特化Kernel模板类，一般无需特化，因为这个类里面一般会做一些通用工作，然后将实际的计算转到Functor模板类中</li><li>重写Kernel的Compute方法，利用OpKernelContext获取输出，分配输出，并进行合法性检查，然后转调对应的计算Functor</li><li>注册Kernel</li></ul><p>很多重要的api都在<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/core/framework/op_kernel.h#L224" target="_blank" rel="external">OpKernelConstruction</a>和<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/core/framework/op_kernel.h#L459" target="_blank" rel="external">OpKernelContext</a>两个类里面建议详细阅读。同时Compute方法必须是线程安全的，因此任何对类成员的访问必须要用互斥保护。</p><p>在转到实际的计算函数前通常会把输入输出Tensor的缓冲区取出来，要么变成Eigen的表示即<a href="https://eigen.tuxfamily.org/dox/unsupported/TensorMap_8h_source.html" target="_blank" rel="external">TensorMap</a>（其对应的很多成员要去<a href="https://eigen.tuxfamily.org/dox/unsupported/TensorBase_8h_source.html" target="_blank" rel="external">TensorBase</a>里面去找），要么更进一步直接再调用TensorMap的data方法把缓冲区指针取出来传给计算函数。具体地，可以去看<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/core/framework/tensor.h#L51" target="_blank" rel="external">Tensor</a>这个类提供的一些接口。</p><p>计算的实现过程不细说，可以直接上C，可以用std::thread保证移植性，也可以利用强大的Eigen，里面有很好的并行化机制根据每个执行单元的cost来分配线程资源，还可以利用Tensorflow提供的对Eigen进行包装后的<a href="https://github.com/tensorflow/tensorflow/blob/aa729b1aac8a2a4939fd3b208510caea645ddd87/tensorflow/core/util/work_sharder.h#L48" target="_blank" rel="external">Shard</a>（这个头文件需要自己加）工具类，下面的代码是一个使用示例：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">auto</span> work_routine = [&amp;your_capture](<span class="keyword">int64_t</span> start, <span class="keyword">int64_t</span> limit)&#123;</div><div class="line">  <span class="keyword">for</span> (<span class="keyword">int64_t</span> worker_index = start; worker_index &lt; limit; ++worker_index)&#123;</div><div class="line">  <span class="comment">// do something</span></div><div class="line">  &#125;</div><div class="line">&#125;;</div><div class="line"></div><div class="line"><span class="keyword">const</span> DeviceBase::CpuWorkerThreads&amp; worker_threads = *(context-&gt;device()-&gt;tensorflow_cpu_worker_threads());</div><div class="line"><span class="keyword">const</span> <span class="keyword">int64_t</span> shard_cost = <span class="number">4</span> * num_rois;</div><div class="line">Shard(worker_threads.num_threads, worker_threads.workers, total_elems, shard_cost, work_routine);</div></pre></td></tr></table></figure></p><p>GPU的实现多数简单情况下GetCudaLaunchConfig + CUDA_1D_KERNEL_LOOP就可以搞定，更多有用的接口可以去看<a href="https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/core/util/cuda_kernel_helper.h" target="_blank" rel="external">cuda_kernel_helper.h</a>，也可以借助cub的api或者更暴力一点直接写。顺便说一下，使用Eigen或者Tensorflow的CPU并行化机制编写代码，通常写出的代码整体逻辑和GPU代码基本一致，我在写<a href="https://github.com/HiKapok/PSROIAlign" target="_blank" rel="external">PSROIAlign</a>的时候从CPU代码移植到GPU改动的地方很少。</p><p>OpKernel的注册和Ops的注册比较类似，也是调用一个宏REGISTER_KERNEL_BUILDER，指定名称、Kernel对应的设备类型，以及创建这个Kernel的C++类。详见<a href="https://hikapok.github.io/2018/03/02/how-new-op-works/">Tensorflow是如何注册和调用C++ New Op的</a>。</p><h1 id="创建python接口"><a href="#创建python接口" class="headerlink" title="创建python接口"></a><strong>创建python接口</strong></h1><p>在这之前当然先要对自己写的Op进行编译，我捣鼓了一个CMakeLists感觉很好用，可以把C++和CUDA代码分开编译然后一起链接很省事，只要正确安装了cuda和python包头文件都可以自己找到，推荐给大家<a href="https://github.com/HiKapok/PSROIAlign/blob/master/CMakeLists.txt" target="_blank" rel="external">CMakeLists.txt</a>。</p><p>编译成功后应该可以获得一个动态库文件 .so，python这边load一下然后包装一下就好了，把官方的示例抄过来：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">zero_out_module = tf.load_op_library(<span class="string">'./zero_out.so'</span>)</div><div class="line">zero_out = zero_out_module.zero_out</div></pre></td></tr></table></figure></p><h1 id="实现Op梯度计算"><a href="#实现Op梯度计算" class="headerlink" title="实现Op梯度计算"></a><strong>实现Op梯度计算</strong></h1><p>一般就是python这边要么用tensorflow自带Op进行组合，要么再去调用另一个计算梯度的自定义Op，然后整个计算过程放在一个函数里面，用@ops.RegisterGradient修饰一下就行了，具体可参见官方文档。</p><h1 id="测试Op"><a href="#测试Op" class="headerlink" title="测试Op"></a><strong>测试Op</strong></h1><p>同样官方有示例，推荐一个tf.test里面的<a href="https://www.tensorflow.org/api_docs/python/tf/test/compute_gradient" target="_blank" rel="external">compute_gradient</a>和<a href="https://www.tensorflow.org/api_docs/python/tf/test/compute_gradient_error" target="_blank" rel="external">compute_gradient_error</a>，很好用。注意这两个函数计算的并不是梯度，而是输出对输入的Jacobian，计算梯度值要用tf.gradients，tf.test中的那两个函数也是基于<a href="https://www.tensorflow.org/api_docs/python/tf/gradients" target="_blank" rel="external">tf.gradients</a>。其中compute_gradient来计算理论和数值Jacobian，compute_gradient_error计算二者之间的误差。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h1><p>最后总结一下我目前遇到的坑：</p><ul><li>最好不要用Eigen接口，除非你对Eigen比较熟，否则建议使用前阅读以下<a href="http://eigen.tuxfamily.org/dox/TopicLazyEvaluation.html" target="_blank" rel="external">Lazy Evaluation and Aliasing</a>和<a href="https://eigen.tuxfamily.org/dox/TopicPitfalls.html" target="_blank" rel="external">Common pitfalls</a></li><li>用Shard工具类写CPU端的kernel，方便移植到GPU上，但要注意线程间的同步</li><li>全局一致的常量输入使用op的Attr来指定，尤其是需要基于这些常量输入做进一步地运算的时候，因为如果将常量输入作为Scalar类型的Tensor输入，那么在CPU上和GPU上运行时这些输入将在不同的内存里，如果要基于这些常量做进一步地运算在GPU上要用cuda kernel，不利于代码结构的简化</li><li>输出记得先清零</li></ul><p>此外，如果你希望静态链接你的Op，那么可以把代码放在Tensorflow源代码的<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/user_ops" target="_blank" rel="external">user_ops</a>目录下，然后在<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/user_ops/BUILD" target="_blank" rel="external">BUILD</a>文件里添加一个tf_custom_op_library就可以了。</p><p>暂时想到的就这么多，最后祝大家炼丹顺利~~找到理想工作。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Tensorflow提供了大量的基本操作使得我们能够任意组合来实现我们需要的复杂操作，但有时候我们需要的操作不太容易通过这些基本操作来组合，或者复杂的组合方式带来严重的性能开销，这时我们可能会考虑去使用&lt;a href=&quot;https://www.tensorflow.org/
      
    
    </summary>
    
      <category term="深度学习" scheme="https://hikapok.github.io/categories/deeplearning/"/>
    
    
      <category term="机器学习" scheme="https://hikapok.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://hikapok.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="C++" scheme="https://hikapok.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>线性回归和逻辑回归模型的基本假设</title>
    <link href="https://hikapok.github.io/2018/02/28/assumption-of-basic-ml/"/>
    <id>https://hikapok.github.io/2018/02/28/assumption-of-basic-ml/</id>
    <published>2018-02-28T12:41:59.000Z</published>
    <updated>2018-03-01T03:12:14.992Z</updated>
    
    <content type="html"><![CDATA[<p>对机器学习刚入门的同学很容易对一些基本概念混淆不清，尤其是当下Python中一些的工具包进一步降低了ML相关的实践。本文重点探讨一下统计学习理论中一些基础模型的应用假设。不过，首先我觉得有必要澄清一些基本概念。</p><h1 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a><strong>线性模型</strong></h1><p>何为线性模型？看似简单的问题却不一定能答得很好，初学者也容易被数学中线性这一概念所“误导”。</p><ul><li><strong>线性回归模型或线性分类器</strong></li></ul><p>在本文中这二者较为类似，以线性回归模型为例。给定一组随机抽取的样本$\mathbf{X_i} = X_{ij}$及其观测值$Y_i$，其中$i=1,…,N$，$j=1,…,p$，$p$是特征维数也是下面公式中非线性基函数的个数，线性回归模型定义为$$Y_i=\beta_0 + \beta_1\phi_1(X_{i1}) + \cdot + \beta_p\phi_p(X_{ip}) + \varepsilon_i$$<br>其中$\beta_j$是回归系数，可以用来评估每个分量在预测中的重要性，$\phi_j$是非线性基函数，$\varepsilon_t$是回归残差。这里的线性指的是回归系数是$\beta_j$线性的，同时预测值也是$\beta_j$的线性组合。</p><ul><li><strong>时间序列分析中的线性模型</strong></li></ul><p>在基于时间序列的分析和预测中，线性模型指的是某时刻随机变量的预测值是之前若干时刻的随机变量取值的线性函数，通俗来讲就是线性组合。比如随机过程中的一个叫作自回归(Autoregressive, AR)的模型就是一个经典的例子。以$AR(p)$来表示$p$阶自回归模型，则$AR(p)$可定义如下$$ X_t = c + \sum_{i=1}^p\varphi _iX_{t-i} + \varepsilon_t $$<br>其中$\varphi _1,…,\varphi _p$是模型参数，$\varepsilon_t$是残差满足独立高斯分布，$c$是常数项。这里的线性一词并不是指模型参数$\varphi _i$是线性的，这和线性回归模型是不一样的。</p><h1 id="线性回归模型的基本假设"><a href="#线性回归模型的基本假设" class="headerlink" title="线性回归模型的基本假设"></a><strong>线性回归模型的基本假设</strong></h1><p>现在进入本文正题，注意这里的讨论只针对基本的模型，一些假设可以通过如采样更多的数据，贝叶斯估计或其它正则化等方法进行弱化。</p><ul><li><em>i.i.d.</em>：样本随机独立抽样，也就是机器学习问题中最基本的独立同分布假设，训练样本和测试样本必须来自同一个潜在数据生成分布</li><li><em>解释分量之间不满足多重共线性，同时样本数不能太少</em>：这两点就能保证设计矩阵$\mathbf{X}$是满秩的（样本数要大于解释分量数），这样$\mathbf{X}^T\mathbf{X}$就有唯一的逆矩阵，这在线性回归的最小平方估计方法中非常重要，保证了回归系数的唯一性。</li><li><em>Error-Free</em>：样本$\mathbf{X_i}$采样过程中没有引入其他噪声，换句话说除了$\mathbf{X_i}$没有其它未知变量可以对$Y_i$对应的真实值产生确定性的影响，违反这一假设所引入的误差称为贝叶斯误差（Bayes error）</li><li><em>回归误差的条件均值为零</em>：这一点其实和上面的是一样的，同样意味着$\mathbf{X_i}$中包含了所有可以解释$Y_i$的分量，即$E[\varepsilon|\mathbf{X}] = 0$</li><li><em>线性假设</em>：预测真实值是回归系数的线性组合</li><li><em>回归误差的方差一致性</em>：回归误差在不同真实值处应具有相同的方差，与$\mathbf{X_i}$及$Y_i$无关，即$Var(\varepsilon|\mathbf{X})=\sigma^2$</li><li><em>回归误差的独立性</em>：承接上一条，$\varepsilon_i$之间应是相互独立的，$\varepsilon \sim N(0,\sigma^2)$，即不取决于是哪一个样本，至于零均值满足第四条自然能够得出</li></ul><h1 id="逻辑回归模型的基本假设"><a href="#逻辑回归模型的基本假设" class="headerlink" title="逻辑回归模型的基本假设"></a><strong>逻辑回归模型的基本假设</strong></h1><ul><li><em>i.i.d.</em>：同上</li><li><em>解释分量之间不满足多重共线性</em>：观察迭代重加权最小平方的公式可以发现与线性回归模型中的这一点类似</li><li><em>对数几率和解释变量之间存在线性关系</em>：保证了回归系数是线性的</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对机器学习刚入门的同学很容易对一些基本概念混淆不清，尤其是当下Python中一些的工具包进一步降低了ML相关的实践。本文重点探讨一下统计学习理论中一些基础模型的应用假设。不过，首先我觉得有必要澄清一些基本概念。&lt;/p&gt;
&lt;h1 id=&quot;线性模型&quot;&gt;&lt;a href=&quot;#线性模
      
    
    </summary>
    
      <category term="机器学习" scheme="https://hikapok.github.io/categories/machinelearning/"/>
    
    
      <category term="机器学习" scheme="https://hikapok.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="统计学习" scheme="https://hikapok.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>手把手教你用Google云平台搭建自己的深度学习工作站</title>
    <link href="https://hikapok.github.io/2018/01/19/intro-to-google-cloud/"/>
    <id>https://hikapok.github.io/2018/01/19/intro-to-google-cloud/</id>
    <published>2018-01-19T08:11:40.000Z</published>
    <updated>2018-03-02T06:39:31.839Z</updated>
    
    <content type="html"><![CDATA[<center> <figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="home.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure> </center><p>Hello，大家好，最近正式启用了自己的博客，一直以来被各种任务缠身，始终没有养成记录自己学习的点滴的习惯。最近忙于申请实习拿到了两个还不错的offer，但无奈一些原因没能去，于是打算接下来做一些别的事情，输出一些质量高的博文就是其中一项。</p><p>自己也算是入行计算机挺久了，一路走来有许多的感慨，包括个人的选择成长规划等等，过段时间也会进行一下总结分享给大家，希望大家能少走弯路。</p><p>第一篇博文专注于利用较少的资金建立一个可以用于深度学习调试的小工作站，从整体上来看谷歌云（Google Cloud Platform，GCP）在这价格、稳定性等方面有很大的优势，但是好像并没有多少介绍这方面的文章，作为新手来讲熟悉这些配置可能要花上一两天，这篇博文目的就是让新手在半小时内配置一个可用的深度学习环境，涉及配置的各种细节以及开发过程的各个方面，欢迎大家一起交流讨论。</p><p>原材料准备：</p><ul><li>支持<strong>VISA双币</strong>支付的信用卡一张</li><li>科学上网工具</li><li>PuTTY或其他终端工具</li><li>FileZilla或其他支持SFTP的客户端</li></ul><h1 id="注册"><a href="#注册" class="headerlink" title="注册"></a><strong>注册</strong></h1><p>首先你需要有一个Google账户，然后登陆<a href="https://cloud.google.com/" target="_blank" rel="external">https://cloud.google.com/</a>点击免费试用进行注册，填写基本信息和相关协议，账户类型选择个人，地址注意与信用卡账单地址一致，注册完成后信用卡账户会被预扣1美元，过会就会返还回来的。</p><h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a><strong>创建项目</strong></h1><p>GCP对资源进行层次化的管理，方便结合Cloud Identity and Access Management (IAM)进行权限控制和统一配置，大到公司部门，小到具体某个虚拟机。对于个人用户来说，我们通常只需按照项目来组织我们的资源，项目可以说是我们创建、管理和监控资源、进行权限管理以及账单管理的基本单位了，新建账户默认包含一个初始项目，你也可以在控制台创建自己的新项目（个人用户默认最多10个项目），假设现在你已经配置好了自己的项目。</p><p>GCP有很多产品，包括大数据平台，存储和数据库服务，AI相关的API等，来帮助企业更快地创建优质的应用，但这些与本文无关，本文集中介绍如何利用Compute Engine Virtual Machines (VMs)来创建一个较为廉价的可供日常学习使用的机器学习/深度学习平台，合理利用这些资源可以让你尽可能少地为高昂的显卡资源自掏腰包。在正式开始之前有以下几点需要说明一下：</p><ul><li><p><strong>快捷入口</strong>：控制台左侧的Tab提供了GCP产品的一些快捷入口，本文主要涉及计算（Compute Engine）、网络（VPC网络）、产品（结算、IAM和管理）和存储（存储），可以先将这些入口钉一下固定在最上面方便一会直接点进去。</p></li><li><p><strong>预算</strong>：作为穷学生一枚本人比较关心钱的问题，虽然有Google赠送的300美元的现金券，我还是一开始就为整个项目（或者以整个计算账号为单位）制定了预算，超出时会自动提醒。费用是每天更新一次，结算周期是半个月，Google会在你花超过100美元或者距上次缴费超过一个月后自动扣款，费用详情可以在结算/交易里查询。</p></li><li><p><strong>配额</strong>：由于每个账号所拥有的资源都有一定的配额，并且GCP默认的GPU配额是0，因此我们需要进行配额调整的申请。具体在IAM和管理/配额里面操作，见图，点击指标下拉框搜索NVIDIA就会看到K80、P100等型号的GPU，把其他资源都反选掉，只保留GPU相关的服务。然后在下面列表里勾选你要选用的GPU型号（注意区域要和待会要创建的VMs所在区域一致），型号根据自己情况进行选择，本人选了K80（12GB内存可以满足我的日常使用），然后选择最上面的修改配额，在右侧弹窗里输入个人电话，目标调整数量以及申请理由，提交即可，我大概等了不到10分钟就调整好了。</p></li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="quato.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h1 id="创建虚拟机"><a href="#创建虚拟机" class="headerlink" title="创建虚拟机"></a><strong>创建虚拟机</strong></h1><p>创建VMs相关的操作都在Compute Engine菜单下，为了节省费用同时不至于太影响训练速度，我只设置了30GB的永久固态硬盘，然后又创建了120GB的永久机械硬盘挂载到实例上。如果你只希望用固态硬盘当做启动盘和数据盘，可以忽略创建磁盘这一步。</p><ul><li><p>创建磁盘<br>Compute Engine/磁盘：点击最上面创建磁盘，输入名称，选择与VMs一致的地区，类型设置为标准永久性磁盘，土豪可以选择SSD永久性磁盘，由于初次使用没有映像或者快照，因此来源类型选无（空白磁盘），待会我们在VMs里面进行格式化和分区操作。大小根据自己需求，建议可以稍大一些，一方面性能会好一些，另一方面各种数据集通常都要来回捣腾，因此最好要比预期数据量大一倍。</p></li><li><p>创建VMs<br>Compute Engine/VM实例：点创建，输入名称，这个名称会作为计算机名，选择与GPU和磁盘一致的区域，机器类型勾选自定义，我选的是4vCPU、8GB内存、1个K80 GPU，详单见图。启动磁盘选更改进行配置，选择Ubuntu 16.04 LTS操作系统镜像，如果我们之前对自己创建的虚拟机备份过映像这里可以直接选上，启动磁盘类型建议选择SSD大小自己配置，如果你之前有删除实例后剩下的启动磁盘想直接用可以在现有磁盘下面勾选，前提是里面要有操作系统。</p></li></ul><center> <figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="creatvm.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure> </center><p>防火墙一栏勾上允许HTTP流量和HTTPS流量。下方磁盘那个Tab可以设置是否在删除实例时也把启动盘删除，这里我们在额外磁盘下面选择添加一项把之前创建的数据磁盘挂上来。管理Tab里面可以设置启动脚本，方便每次开机时进行系统更新、外部磁盘挂载等操作，这里我先没有设置，因为后面可以在弄好机器后在更改元数据里面重新设置。此外如果你不需要长时间训练模型那么可以开启抢占式VM，缺点就是随时都可能被终止（大约10%~20%的概率，实际由对应区域用量决定），即使由于整个区域用量较小没有被停掉24小时之后也会被终止，如果刚开启虚拟机10分钟之内被抢占是不收费的，需要注意的是抢占式VM的资源总量是有限的，也就是说并不是什么时候想用什么时候就有。</p><p>SSH密钥那个Tab里面我们需要配置一下以便使用其它终端工具对VM进行操作，GCP也自带基于浏览器的一种终端，感觉也不错，但是比较慢。终端工具根据自己习惯选择，这里以PuTTY为例进行配置。PuTTY带有一个密钥生成工具PuTTYgen，打开界面如下：</p><center> <figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="puttygen.PNG" alt="" title="">                </div>                <div class="image-caption"></div>            </figure> </center><p>点击generate然后在空白区域来回晃几下鼠标就会生成一个ssh-rsa密钥，comment改成自己的用户名，VM会自动创建对应的账户，然后复制Public key（就是以ssh-rsa开头的最长的那个）粘贴到GCP刚才那个Tab里面，点创建等几分钟即可。接下来我们需要把刚才生成的密钥保存在同一个目录，保存private key的时候会提示设置密码。保存完毕后需要打开PuTTY新建一个session，这会VM实例应该也创建完毕，把外部ip地址填进来，然后在Connection-&gt;SSH-&gt;Auth属性页最下面把保存的private key加载进来，最后打开连接，安全提示选是然后就可以连接到虚拟机了。</p><p>如果你想直接用在线的SSH的话，直接在Compute Engine/VM实例里面点SSH，可以通过这个工具上传下载一些简单的文件之类的。</p><ul><li>设置数据磁盘</li></ul><p>数据磁盘本身是空白磁盘，虽然被接进来了，但必须进行格式化分区之后才可以挂载。以下命令帮你查看数据磁盘是不是真的连接进来了，并查看对应的设备号，我这里是sdb。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo fdisk –l</div></pre></td></tr></table></figure><p>接下来我们需要对空白磁盘进行分区，同样是使用fdisk命令进入一个交互式的环境，这个环境下所有的操作都不会立刻写进分区表，除非显式地通过w保存操作：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo fdisk /dev/sdb</div></pre></td></tr></table></figure><p>根据相应的快捷键提示可以很容易完成分区，我的整个磁盘只有一个分区，如果你的磁盘很大也可以分多个区，n新建分区，d删除分区，w保存分区表，q不保存直接退出。</p><p>如果你也是只分了一个区，那么你应该会得到一个名为sdb1的新设备，下面命令完成格式化，你也可以换成ntfs格式，这里使用linux格式：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo mkfs.ext4 /dev/sdb1</div></pre></td></tr></table></figure><p>接下来我们在/media目录下新建一个挂载点（我这里名称为disk），把刚才格式化好的设备挂载进来：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo mkdir /media/disk</div><div class="line">sudo mount /dev/sdb1 /media/disk</div></pre></td></tr></table></figure><p>如果你不想每次开机都手动挂载这个设备的话，可以设置上面说到的那个启动脚本，启动脚本的设置需要在关机状态下进行，待会你重启时记得设置：仍然是在Compute Engine/VM实例下面，点击VM的名称进入VM详情页面，点击最上面修改，往下拉找到自定义元数据，键设为startup-script，值设置为下面的脚本内容，然后点保存重启虚拟机。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#! /bin/bash</span></div><div class="line">mount /dev/sdb1 /media/disk</div></pre></td></tr></table></figure><p>同样的方法也可以设置shutdown-script，可以在关机或被抢占时保存模型或给自己发个邮件提醒之类的。</p><p>以上步骤完成后，我们还需要设置一下防火墙：</p><p>网络/VPC网络/防火墙规则：然后点击最上面创建防火墙规则，名称default-dev之类，目标选网络中的所有实例，来源 IP 地址范围填0.0.0.0/0，协议和端口填tcp:6000-6010;tcp:8888（这个根据日常开发用到的端口自己决定），其他保持默认。</p><h1 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a><strong>环境配置</strong></h1><p>现在你已经有了一台至少4核8G内存附带一张K80显卡的机器了，接下来就是跟普通机器一样配置环境了。如果你已经很熟悉深度学习之类的环境配置，可以直接跳过这一部分。</p><p>我通常先会按照自己的使用习惯配置一下tmux、git和vim，装一些插件之类的。下面的命令可以帮你把一些大概率会用到的包提前装上，以免后续安装过程卡壳：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev valgrind cmake unrar gfortran python3-pip python3-dev python3-wheel swig git git-core htop</div></pre></td></tr></table></figure><p>建议日常的机器学习之类的调试训练都在虚拟环境下进行，虚拟环境配置可以参考下面命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install python-pip python-setuptools</div><div class="line">sudo pip install --upgrade pip</div><div class="line">sudo pip install virtualenv</div><div class="line">curl -L https://raw.github.com/yyuu/pyenv-installer/master/bin/pyenv-installer | bash</div></pre></td></tr></table></figure><p>设置虚拟环境对应的环境变量</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo vim ~/.bash_profile</div></pre></td></tr></table></figure><p>在文件最后加上下面这些内容：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> PATH=<span class="string">"/home/yourname/.pyenv/bin:<span class="variable">$PATH</span>"</span></div><div class="line"><span class="built_in">eval</span> <span class="string">"<span class="variable">$(pyenv init -)</span>"</span></div><div class="line"><span class="built_in">eval</span> <span class="string">"<span class="variable">$(pyenv virtualenv-init -)</span>"</span></div></pre></td></tr></table></figure><p>生效更改然后安装python 3.5.2：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">source</span> ~/.bash_profile</div><div class="line">pyenv install 3.5.2</div></pre></td></tr></table></figure><p>注意把默认的python设置为系统对应的python版本</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看可用的python版本，注意默认版本</span></div><div class="line">pyenv versions</div><div class="line"><span class="comment"># 把默认版本设为系统自带的python版本</span></div><div class="line">pyenv global system</div></pre></td></tr></table></figure><p>在当前目录下创建一个名为pyenv35的虚拟环境</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">virtualenv -p .pyenv/versions/3.5.2/bin/python3.5 pyenv35</div></pre></td></tr></table></figure><p>激活刚创建的虚拟环境</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">source</span> pyenv35/bin/activate</div></pre></td></tr></table></figure><p>安装常用机器学习包（这个根据自己的需求来）</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pyenv35/bin/pip3.5 install numpy scipy matplotlib pandas seaborn sklearn lightgbm xgboost tqdm</div></pre></td></tr></table></figure><p>安装CUDA运行时环境</p><p>首先确认一下系统应该至少没有安装除nvidia-common之外的任何nvidia的包：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dpkg -l | grep -i nvidia</div></pre></td></tr></table></figure><p>否则使用以下命令删除多余的包及配置文件：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo apt-get remove --purge name_of_ package</div><div class="line">sudo apt-get autoremove</div></pre></td></tr></table></figure><p>然后我们需要下载CUDA的安装包和cuDNN：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb</div><div class="line">sudo wget http://developer.download.nvidia.com/compute/redist/cudnn/v6.0/cudnn-8.0-linux-x64-v6.0.tgz</div><div class="line">sudo wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/patches/2/cuda-repo-ubuntu1604-8-0-local-cublas-performance-update_8.0.61-1_amd64-deb</div></pre></td></tr></table></figure><p>接下来安装驱动和运行时：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo dpkg -i cuda-repo-ubuntu1604_8.0.61-1_amd64.deb</div><div class="line">sudo dpkg -i cuda-repo-ubuntu1604-8-0-local-cublas-performance-update_8.0.61-1_amd64.deb</div><div class="line">sudo apt-get update</div></pre></td></tr></table></figure><p>查看可用的CUDA运行时版本：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-cache policy cuda</div></pre></td></tr></table></figure><p>安装CUDA8.0</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install cuda=8.0.61-1</div></pre></td></tr></table></figure><p>添加源并更新到最新驱动：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo add-apt-repository ppa:graphics-drivers/ppa</div></pre></td></tr></table></figure><p>这里记得需要敲回车键确认添加源</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo apt-get update</div><div class="line">sudo apt-get upgrade</div><div class="line">sudo reboot</div></pre></td></tr></table></figure><p>安装cuDNN</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">tar -xvf cudnn-8.0-linux-x64-v6.0.tgz</div><div class="line">sudo cp cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/include</div><div class="line">sudo cp cuda/lib64/libcudnn* /usr/<span class="built_in">local</span>/cuda/lib64</div><div class="line">sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/lib64/libcudnn*</div></pre></td></tr></table></figure><p>设置环境变量：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo vim ~/.bashrc</div></pre></td></tr></table></figure><p>在文件最后添加下面内容：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="string">"<span class="variable">$LD_LIBRARY_PATH</span>:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64"</span></div><div class="line"><span class="built_in">export</span> CUDA_HOME=/usr/<span class="built_in">local</span>/cuda</div><div class="line"><span class="built_in">export</span> PATH=<span class="string">"<span class="variable">$CUDA_HOME</span>/bin:<span class="variable">$PATH</span>"</span></div></pre></td></tr></table></figure><p>生效更改</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">source</span> ~/.bashrc</div></pre></td></tr></table></figure><p>最后敲nvidia-smi确认驱动安装成功</p><h1 id="安装深度学习工具包"><a href="#安装深度学习工具包" class="headerlink" title="安装深度学习工具包"></a><strong>安装深度学习工具包</strong></h1><p>安装bazel、tensorflow-gpu、PyTorch、MxNet</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install openjdk-8-jdk</div><div class="line"><span class="built_in">echo</span> <span class="string">"deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8"</span> | sudo tee /etc/apt/sources.list.d/bazel.list</div><div class="line">curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -</div><div class="line">sudo apt-get update &amp;&amp; sudo apt-get install bazel</div></pre></td></tr></table></figure><p>先进入虚拟环境，然后执行以下命令安装：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pyenv35/bin/pip3.5 install opencv-python tensorflow-gpu http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp35-cp35m-linux_x86_64.whl torchvision mxnet-cu80==1.0.0</div></pre></td></tr></table></figure><p>配置远程jupyter notebook</p><p>仍然是在虚拟环境下，安装notebook:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pyenv35/bin/pip3.5 install jupyter notebook</div></pre></td></tr></table></figure><p>进入python交互式环境，生成hash密码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</div><div class="line">passwd()</div></pre></td></tr></table></figure><p>输入密码并记下形如’sha1:daa96*06c24059c807b08’的字串。</p><p>在bash里输入下面的命令生成notebook配置文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">jupyter notebook --generate-config</div></pre></td></tr></table></figure><p>编辑配置文件，设置密码和权限等：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo vim .jupyter/jupyter_notebook_config.py</div></pre></td></tr></table></figure><p>设置以下几项并保存：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">c.NotebookApp.ip = <span class="string">'*'</span></div><div class="line">c.NotebookApp.password = u<span class="string">'sha1:daa96*06c24059c807b08'</span></div><div class="line">c.NotebookApp.open_browser = False</div><div class="line">c.NotebookApp.port = 8888</div></pre></td></tr></table></figure><p>执行jupyter notebook打开notebook，然后在本地浏览器打开<a href="http://yourip:8888" target="_blank" rel="external">http://yourip:8888</a>，如果正常的话，输入密码就可以使用了。如果有问题可以确认一下防火墙。</p><p>现在是时候去网上找一些测试代码来确认安装过程的正确性了。</p><h1 id="文件共享"><a href="#文件共享" class="headerlink" title="文件共享"></a><strong>文件共享</strong></h1><p>本想按照往常一样安装samba将虚拟机的磁盘映射到windows系统网络驱动器来传文件，但是搞了半天老是连不通，有知道解决方案的知友欢迎留言。因此目前只能采用FileZilla通过SFTP给VMs传文件的方式。操作如下：</p><p>打开FileZilla-&gt;文件-&gt;站点管理器-&gt;新站点：主机填VM的外部ip，协议选择SFTP，登录类型选择密码文件，然后把之前用PuTTY生成的私钥加载进来，高级选项卡里面可以设置本地目录和远程目录。最后点连接就行了，如果有问题的话可以检查一下远程目录的权限，我试了一下传输速度还挺快。</p><p>还有一点，日常的开发工作除了用notebook远程连接外，还可以在SublimeText下面使用SFTP的插件，配置过程跟上面文件传输的配置类似。</p><p>好了现在就应该都大功告成了，最后别忘了为配置好的系统制作映像，以便将来重新安装：</p><p>Compute Engine-&gt;映像-&gt;创建映像。</p><p>最近会抽空更新几篇机器学习相关的文章，欢迎大家关注，也欢迎大家讨论交流、指出问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;center&gt; &lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
          
      
    
    </summary>
    
      <category term="其它" scheme="https://hikapok.github.io/categories/others/"/>
    
    
      <category term="机器学习" scheme="https://hikapok.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://hikapok.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="环境配置" scheme="https://hikapok.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://hikapok.github.io/2017/10/16/hello-world/"/>
    <id>https://hikapok.github.io/2017/10/16/hello-world/</id>
    <published>2017-10-16T08:42:43.371Z</published>
    <updated>2017-10-02T15:52:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
